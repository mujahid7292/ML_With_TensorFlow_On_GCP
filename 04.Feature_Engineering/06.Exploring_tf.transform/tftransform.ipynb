{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Exploring tf.transform </h1>\n",
    "\n",
    "While Pandas is fine for experimenting, for operationalization of your workflow, it is better to do preprocessing in Apache Beam. This will also help if you need to preprocess data in flight, since Apache Beam also allows for streaming.\n",
    "\n",
    "Only specific combinations of TensorFlow/Beam are supported by tf.transform. So make sure to get a combo that is.\n",
    "\n",
    "* TFT 0.8.0\n",
    "* TF 1.8 or higher\n",
    "* Apache Beam [GCP] 2.9.0 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apache-beam[gcp]==2.16.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (2.16.0)\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/18/62/08/7b4aee4bd80bd969f9c9c653556b0c8732c9c1fbff18a2b26d/tensorflow_transform-0.15.0-cp37-none-any.whl\n",
      "Requirement already satisfied: avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.9.2.1)\n",
      "Requirement already satisfied: pyarrow<0.15.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.14.1)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (2.0.0)\n",
      "Requirement already satisfied: oauth2client<4,>=2.0.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.0.0)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (2.5.8)\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f/PyYAML-3.13-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.7)\n",
      "Requirement already satisfied: httplib2<=0.12.0,>=0.8 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.12.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.10.1)\n",
      "Requirement already satisfied: dill<0.3.1,>=0.3.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.3.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.12.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.27.2)\n",
      "Requirement already satisfied: fastavro<0.22,>=0.21.4 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.21.24)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2018.3 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (2019.3)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.18.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.11.3)\n",
      "Requirement already satisfied: google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.17.1)\n",
      "Requirement already satisfied: google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (0.5.28)\n",
      "Requirement already satisfied: google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.7.4)\n",
      "Requirement already satisfied: google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.0.2)\n",
      "Requirement already satisfied: cachetools<4,>=3.1.0; extra == \"gcp\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (3.1.1)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.3.0)\n",
      "Requirement already satisfied: google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from apache-beam[gcp]==2.16.0) (1.0.0)\n",
      "Requirement already satisfied: tensorflow<2.2,>=1.15 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow_transform==0.15.0) (2.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.16 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow_transform==0.15.0) (1.18.1)\n",
      "Requirement already satisfied: absl-py<0.9,>=0.7 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow_transform==0.15.0) (0.8.1)\n",
      "Requirement already satisfied: six<2,>=1.10 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow_transform==0.15.0) (1.14.0)\n",
      "Collecting tensorflow-metadata<0.16,>=0.15\n",
      "  Using cached https://files.pythonhosted.org/packages/3b/0c/afb81ea6998f6e26521671585d1cd9d3f7945a8b9834764e91757453dc25/tensorflow_metadata-0.15.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tfx-bsl<0.16,>=0.15 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow_transform==0.15.0) (0.15.3)\n",
      "Requirement already satisfied: pbr>=0.11 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.16.0) (5.4.4)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0) (4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0) (0.2.8)\n",
      "Requirement already satisfied: requests>=2.7.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (2.23.0)\n",
      "Requirement already satisfied: docopt in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (0.6.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from pydot<2,>=1.2.0->apache-beam[gcp]==2.16.0) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from protobuf<4,>=3.5.0.post1->apache-beam[gcp]==2.16.0) (46.0.0)\n",
      "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (0.4.1)\n",
      "Requirement already satisfied: fasteners>=0.14 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (0.15)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.6.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (1.16.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (0.12.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (0.1.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (0.2.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (1.4.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (3.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (0.33.6)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (1.11.2)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (2.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (1.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow-metadata<0.16,>=0.15->tensorflow_transform==0.15.0) (1.51.0)\n",
      "Requirement already satisfied: psutil<6,>=5.6 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tfx-bsl<0.16,>=0.15->tensorflow_transform==0.15.0) (5.6.3)\n",
      "Requirement already satisfied: tensorflow-serving-api<3,>=1.15 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tfx-bsl<0.16,>=0.15->tensorflow_transform==0.15.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0) (1.25.8)\n",
      "Requirement already satisfied: monotonic>=0.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (1.5)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0) (1.11.2)\n",
      "Requirement already satisfied: h5py in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (2.9.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (0.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=1.15->tensorflow_transform==0.15.0) (3.1.0)\n",
      "Installing collected packages: tensorflow-metadata, tensorflow-transform, pyyaml\n",
      "  Found existing installation: tensorflow-metadata 0.14.0\n",
      "    Uninstalling tensorflow-metadata-0.14.0:\n",
      "      Successfully uninstalled tensorflow-metadata-0.14.0\n",
      "  Found existing installation: tensorflow-transform 0.14.0\n",
      "    Uninstalling tensorflow-transform-0.14.0:\n",
      "      Successfully uninstalled tensorflow-transform-0.14.0\n",
      "  Found existing installation: PyYAML 5.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'pip install apache-beam[gcp]==2.16.0 tensorflow_transform==0.15.0\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b4ee00b8adad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pip install apache-beam[gcp]==2.16.0 tensorflow_transform==0.15.0\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/mujahid7292/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'pip install apache-beam[gcp]==2.16.0 tensorflow_transform==0.15.0\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install apache-beam[gcp]==2.16.0 tensorflow_transform==0.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Restart the kernel</b> after you do a pip install (click on the reload button above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apache-beam==2.16.0\n",
      "tensorflow==2.1.0\n",
      "tensorflow-datasets==1.2.0\n",
      "tensorflow-estimator==2.1.0\n",
      "tensorflow-metadata==0.15.2\n",
      "tensorflow-serving-api==2.1.0\n",
      "tensorflow-transform==0.15.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep -e 'flow\\|beam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input source: BigQuery\n",
    "\n",
    "Get data from BigQuery but defer filtering etc. to Beam.\n",
    "Note that the dayofweek column is now strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1=train 2=valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "WITH daynames AS\n",
    "  (SELECT ['Sun', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat'] AS daysofweek)\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  daysofweek[ORDINAL(EXTRACT(DAYOFWEEK FROM pickup_datetime))] AS dayofweek,\n",
    "  EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count AS passengers,\n",
    "  'notneeded' AS key\n",
    "FROM\n",
    "  `nyc-tlc.yellow.trips`, daynames\n",
    "WHERE\n",
    "  trip_distance > 0 AND fare_amount > 0\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # training\n",
    "      query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)),4) < 2\".format(base_query)\n",
    "    else:\n",
    "      query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)),4) = {1}\".format(base_query, phase)\n",
    "  else:\n",
    "      query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))),{1}) = {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(2, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = bigquery.Client().query(query).to_dataframe()\n",
    "display(df_valid.head())\n",
    "df_valid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ML dataset using tf.transform and Dataflow\n",
    "\n",
    "Let's use Cloud Dataflow to read in the BigQuery data and write it out as CSV files. Along the way, let's use tf.transform to do scaling and transforming. Using tf.transform allows us to save the metadata to ensure that the appropriate transformations get carried out during prediction as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "tensorflow-transform==0.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test transform_data is type pcollection. test if _ = is neccesary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.beam import impl as beam_impl\n",
    "\n",
    "def is_valid(inputs):\n",
    "  try:\n",
    "    pickup_longitude = inputs['pickuplon']\n",
    "    dropoff_longitude = inputs['dropofflon']\n",
    "    pickup_latitude = inputs['pickuplat']\n",
    "    dropoff_latitude = inputs['dropofflat']\n",
    "    hourofday = inputs['hourofday']\n",
    "    dayofweek = inputs['dayofweek']\n",
    "    passenger_count = inputs['passengers']\n",
    "    fare_amount = inputs['fare_amount']\n",
    "    return (fare_amount >= 2.5 and pickup_longitude > -78 and pickup_longitude < -70 \\\n",
    "      and dropoff_longitude > -78 and dropoff_longitude < -70 and pickup_latitude > 37 \\\n",
    "      and pickup_latitude < 45 and dropoff_latitude > 37 and dropoff_latitude < 45 \\\n",
    "      and passenger_count > 0)\n",
    "  except:\n",
    "    return False\n",
    "  \n",
    "def preprocess_tft(inputs):\n",
    "      import datetime   \n",
    "      print inputs\n",
    "      result = {}\n",
    "      result['fare_amount'] = tf.identity(inputs['fare_amount'])     \n",
    "      result['dayofweek'] = tft.string_to_int(inputs['dayofweek']) # builds a vocabulary\n",
    "      result['hourofday'] = tf.identity(inputs['hourofday']) # pass through\n",
    "      result['pickuplon'] = (tft.scale_to_0_1(inputs['pickuplon'])) # scaling numeric values\n",
    "      result['pickuplat'] = (tft.scale_to_0_1(inputs['pickuplat']))\n",
    "      result['dropofflon'] = (tft.scale_to_0_1(inputs['dropofflon']))\n",
    "      result['dropofflat'] = (tft.scale_to_0_1(inputs['dropofflat']))\n",
    "      result['passengers'] = tf.cast(inputs['passengers'], tf.float32) # a cast\n",
    "      result['key'] = tf.as_string(tf.ones_like(inputs['passengers'])) # arbitrary TF func\n",
    "      # engineered features\n",
    "      latdiff = inputs['pickuplat'] - inputs['dropofflat']\n",
    "      londiff = inputs['pickuplon'] - inputs['dropofflon']\n",
    "      result['latdiff'] = tft.scale_to_0_1(latdiff)\n",
    "      result['londiff'] = tft.scale_to_0_1(londiff)\n",
    "      dist = tf.sqrt(latdiff * latdiff + londiff * londiff)\n",
    "      result['euclidean'] = tft.scale_to_0_1(dist)\n",
    "      return result\n",
    "\n",
    "def preprocess(in_test_mode):\n",
    "  import os\n",
    "  import os.path\n",
    "  import tempfile\n",
    "  from apache_beam.io import tfrecordio\n",
    "  from tensorflow_transform.coders import example_proto_coder\n",
    "  from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "  from tensorflow_transform.tf_metadata import dataset_schema\n",
    "  from tensorflow_transform.beam import tft_beam_io\n",
    "  from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "\n",
    "  job_name = 'preprocess-taxi-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "  if in_test_mode:\n",
    "    import shutil\n",
    "    print 'Launching local job ... hang on'\n",
    "    OUTPUT_DIR = './preproc_tft'\n",
    "    shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "    EVERY_N = 100000\n",
    "  else:\n",
    "    print 'Launching Dataflow job {} ... hang on'.format(job_name)\n",
    "    OUTPUT_DIR = 'gs://{0}/taxifare/preproc_tft/'.format(BUCKET)\n",
    "    import subprocess\n",
    "    subprocess.call('gsutil rm -r {}'.format(OUTPUT_DIR).split())\n",
    "    EVERY_N = 10000\n",
    "    \n",
    "  options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': job_name,\n",
    "    'project': PROJECT,\n",
    "    'max_num_workers': 6,\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True,\n",
    "    'requirements_file': 'requirements.txt'\n",
    "  }\n",
    "  opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "  if in_test_mode:\n",
    "    RUNNER = 'DirectRunner'\n",
    "  else:\n",
    "    RUNNER = 'DataflowRunner'\n",
    "\n",
    "  # set up raw data metadata\n",
    "  raw_data_schema = {\n",
    "    colname : dataset_schema.ColumnSchema(tf.string, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in 'dayofweek,key'.split(',')\n",
    "  }\n",
    "  raw_data_schema.update({\n",
    "      colname : dataset_schema.ColumnSchema(tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in 'fare_amount,pickuplon,pickuplat,dropofflon,dropofflat'.split(',')\n",
    "    })\n",
    "  raw_data_schema.update({\n",
    "      colname : dataset_schema.ColumnSchema(tf.int64, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in 'hourofday,passengers'.split(',')\n",
    "    })\n",
    "  raw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.Schema(raw_data_schema))\n",
    "\n",
    "  # run Beam  \n",
    "  with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "    with beam_impl.Context(temp_dir=os.path.join(OUTPUT_DIR, 'tmp')):\n",
    "      # save the raw data metadata\n",
    "      raw_data_metadata | 'WriteInputMetadata' >> tft_beam_io.WriteMetadata(\n",
    "            os.path.join(OUTPUT_DIR, 'metadata/rawdata_metadata'),\n",
    "            pipeline=p)\n",
    "      \n",
    "      # read training data from bigquery and filter rows     \n",
    "      raw_data = (p \n",
    "        | 'train_read' >> beam.io.Read(beam.io.BigQuerySource(query=create_query(1, EVERY_N), use_standard_sql=True))\n",
    "        | 'train_filter' >> beam.Filter(is_valid))\n",
    "      raw_dataset = (raw_data, raw_data_metadata)\n",
    "      \n",
    "      # analyze and transform training data\n",
    "      transformed_dataset, transform_fn = (\n",
    "          raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocess_tft))\n",
    "      transformed_data, transformed_metadata = transformed_dataset\n",
    "      \n",
    "      # save transformed training data to disk in efficient tfrecord format\n",
    "      transformed_data | 'WriteTrainData' >> tfrecordio.WriteToTFRecord(\n",
    "          os.path.join(OUTPUT_DIR, 'train'),\n",
    "          file_name_suffix='.gz',\n",
    "          coder=example_proto_coder.ExampleProtoCoder(\n",
    "              transformed_metadata.schema))\n",
    "      \n",
    "      # read eval data from bigquery and filter rows  \n",
    "      raw_test_data = (p \n",
    "        | 'eval_read' >> beam.io.Read(beam.io.BigQuerySource(query=create_query(2, EVERY_N), use_standard_sql=True))\n",
    "        | 'eval_filter' >> beam.Filter(is_valid))\n",
    "      raw_test_dataset = (raw_test_data, raw_data_metadata)\n",
    "      \n",
    "      # transform eval data\n",
    "      transformed_test_dataset = (\n",
    "          (raw_test_dataset, transform_fn) | beam_impl.TransformDataset())\n",
    "      transformed_test_data, _ = transformed_test_dataset\n",
    "      \n",
    "      # save transformed training data to disk in efficient tfrecord format\n",
    "      transformed_test_data | 'WriteTestData' >> tfrecordio.WriteToTFRecord(\n",
    "          os.path.join(OUTPUT_DIR, 'eval'),\n",
    "          file_name_suffix='.gz',\n",
    "          coder=example_proto_coder.ExampleProtoCoder(\n",
    "              transformed_metadata.schema))\n",
    "      \n",
    "      # save transformation function to disk for use at serving time\n",
    "      transform_fn | 'WriteTransformFn' >> transform_fn_io.WriteTransformFn(\n",
    "          os.path.join(OUTPUT_DIR, 'metadata'))\n",
    "\n",
    "preprocess(in_test_mode=False) # change to True to run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# ls preproc_tft\n",
    "gsutil ls gs://${BUCKET}/taxifare/preproc_tft/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train off preprocessed data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf taxifare_tft.tar.gz taxi_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:$PWD/taxifare_tft\n",
    "python -m trainer.task \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/taxifare/preproc_tft/train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/taxifare/preproc_tft/eval*\"  \\\n",
    "   --output_dir=./taxi_trained \\\n",
    "   --train_steps=10 --job-dir=/tmp \\\n",
    "   --metadata_path=gs://${BUCKET}/taxifare/preproc_tft/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $PWD/taxi_trained/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/test.json\n",
    "{\"dayofweek\":\"Thu\",\"hourofday\":17,\"pickuplon\": -73.885262,\"pickuplat\": 40.773008,\"dropofflon\": -73.987232,\"dropofflat\": 40.732403,\"passengers\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "model_dir=$(ls $PWD/taxi_trained/export/exporter/)\n",
    "gcloud ai-platform local predict \\\n",
    "    --model-dir=./taxi_trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=/tmp/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016-2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
