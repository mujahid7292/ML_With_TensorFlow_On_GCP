{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring tf.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Pandas is fine for experimenting, for operationalization of your workflow, it is better to do preprocessing in Apache Beam. This will also help if you need to preprocess data in flight, since Apache Beam also allows for streaming.\n",
    "\n",
    "Only specific combinations of TensorFlow/Beam are supported by tf.transform. So make sure to get a combo that is.\n",
    "\n",
    "* TFT 0.8.0\n",
    "* TF 1.8 or higher\n",
    "* Apache Beam [GCP] 2.9.0 or higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Virtualenv package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "python3-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.1).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  gir1.2-geocodeglib-1.0 libfwup1 ubuntu-web-launchers\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
      "pip 19.3.1 from /home/mujahid7292/anaconda3/lib/python3.7/site-packages/pip (python 3.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sudo] password for mujahid7292: \n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Run Below Command In Terminal\n",
    "echo M01121989u | sudo -S apt install --upgrade python3-pip\n",
    "pip3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: virtualenv in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already up-to-date: filelock<4,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv)\n",
      "Requirement already up-to-date: distlib<1,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv)\n",
      "Requirement already up-to-date: importlib-resources<2,>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from virtualenv)\n",
      "Requirement already up-to-date: six<2,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv)\n",
      "Requirement already up-to-date: appdirs<2,>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from virtualenv)\n",
      "Requirement already up-to-date: importlib-metadata<2,>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from virtualenv)\n",
      "Requirement already up-to-date: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources<2,>=1.0; python_version < \"3.7\"->virtualenv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sudo] password for mujahid7292: The directory '/home/mujahid7292/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n",
      "The directory '/home/mujahid7292/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo M01121989u | sudo -S pip3 install --upgrade virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sudo] password for mujahid7292: The directory '/home/mujahid7292/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n",
      "The directory '/home/mujahid7292/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo M01121989u | sudo -S pip3 install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/04.Feature_Engineering/06.Exploring_tf.transform/Practice\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "Venv = os.getcwd()\n",
    "print(Venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using base prefix '/home/mujahid7292/anaconda3'\n",
      "New python executable in /media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/04.Feature_Engineering/06.Exploring_tf.transform/Practice/Venv/bin/python\n",
      "Installing setuptools, pip, wheel...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "virtualenv Venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activate Virtual Environment For This Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    ". Venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Necessary Package For Running This NoteBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (46.0.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqtwebengine==5.12 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (5.12)\n",
      "Requirement already satisfied: PyQt5>=5.12 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from pyqtwebengine==5.12) (5.12)\n",
      "Requirement already satisfied: PyQt5_sip<4.20,>=4.19.14 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from PyQt5>=5.12->pyqtwebengine==5.12) (4.19.19)\n",
      "Requirement already satisfied: pyqt5==5.12 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (5.12)\n",
      "Requirement already satisfied: PyQt5_sip<4.20,>=4.19.14 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (from pyqt5==5.12) (4.19.19)\n",
      "Collecting six==1.12\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Installing collected packages: six\n",
      "  Found existing installation: six 1.14.0\n",
      "    Uninstalling six-1.14.0:\n",
      "      Successfully uninstalled six-1.14.0\n",
      "Successfully installed six-1.12.0\n",
      "Requirement already satisfied: typed-ast==1.4.0 in /home/mujahid7292/anaconda3/lib/python3.7/site-packages (1.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "ERROR: tfx-bsl 0.15.3 has requirement apache-beam[gcp]<2.17,>=2.16, but you'll have apache-beam 2.19.0 which is incompatible.\n",
      "ERROR: astroid 2.3.1 has requirement wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\n",
      "ERROR: apache-beam 2.19.0 has requirement pyarrow<0.16.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\", but you'll have pyarrow 0.14.1 which is incompatible.\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 install pyqtwebengine==5.12\n",
    "pip3 install pyqt5==5.12\n",
    "pip3 install six==1.12\n",
    "pip3 install typed-ast==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache-beam[gcp]==2.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/54/6835fc8efeef0ff109a1f11452aa583c213cdde19e608ab6f555b51bf394/apache_beam-2.16.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting six==1.12\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/03/05/65/bdc14f2c6e09e82ae3e0f13d021e1b6b2481437ea2f207df3f/PyYAML-3.12-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting python-dateutil<3,>=2.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70/hdfs-2.5.8-cp37-none-any.whl\n",
      "Collecting fastavro<0.22,>=0.21.4\n",
      "  Using cached https://files.pythonhosted.org/packages/af/fa/1c7b265aa44cf6089ce56a2702377a4994632016688b2b9ccde38a884024/fastavro-0.21.24-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting protobuf<4,>=3.5.0.post1\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/f1/8dcd4219bbae8aa44fe8871a89f05eca2dca9c04f8dbfed8a82b7be97a88/protobuf-3.11.3-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/e2/91a313e50adcf35182e260d65cf7ec60f6f0367abefc2fbab264e6f4544d/pymongo-3.10.1-cp37-cp37m-manylinux2014_x86_64.whl\n",
      "Collecting pyarrow<0.15.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\"\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/ef/65cc820e4563c946592cb3d38f33bc342160943231ffae8a9550460f9bb7/pyarrow-0.14.1-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Collecting grpcio<2,>=1.12.1\n",
      "  Using cached https://files.pythonhosted.org/packages/fb/00/997acb1c16f84e6d3ede511500f54e7b7a1fdfe7b4da5a5c2d07ad4e91f1/grpcio-1.27.2-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Collecting mock<3.0.0,>=1.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl\n",
      "Collecting pytz>=2018.3\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Collecting future<1.0.0,>=0.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/c9/de/a4/a91eec4eea652104d8c81b633f32ead5eb57d1b294eab24167/dill-0.3.0-cp37-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/6d/41/4b/2b369d6e2b7eaebcdd423516d3fb659c7658c16a2be8fd04ec/httplib2-0.12.0-cp37-none-any.whl\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Using cached https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/48/f7/87/b932f09c6335dbcf45d916937105a372ab14f353a9ca431d7d/oauth2client-3.0.0-cp37-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/50/24/4d/4580ca4a299f1ad6fd63443e6e584cb21e9a07988e4aa8daac/crcmod-1.7-cp37-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/5a/d3/be/86620c9dd3fca68986c33b9c616510289fc0abb81ec9aa70bd/avro_python3-1.9.2.1-cp37-none-any.whl\n",
      "Collecting google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/95/af/0ef7d097a1d5ad0c843867600e86de915e8ab8864740f49a4636cfb51af6/google_cloud_bigtable-1.0.0-py2.py3-none-any.whl\n",
      "Collecting google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/d0/aa/29cbcf8cf7d08ce2d55b9dce858f7c632b434cb6451bed17cb4275804217/google_cloud_datastore-1.7.4-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/d6/c2/92/837e8a4d649a209dff85b38d7fbb576b4b480738be70865f29/google_apitools-0.5.28-cp37-none-any.whl\n",
      "Collecting google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/91/07a82945a7396ea34debafd476724bb5fc267c292790fdf2138c693f95c5/google_cloud_pubsub-1.0.2-py2.py3-none-any.whl\n",
      "Collecting google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/96/1b9cf1d43869c47a205aad411dac7c3040df6093d63c39273fa4d4c45da7/google_cloud_bigquery-1.17.1-py2.py3-none-any.whl\n",
      "Collecting cachetools<4,>=3.1.0; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-core<2,>=0.28.1; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\n",
      "Collecting requests>=2.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e/docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting setuptools\n",
      "  Using cached https://files.pythonhosted.org/packages/70/b8/b23170ddda9f07c3444d49accde49f2b92f97bb2f2ebc312618ef12e4bd6/setuptools-46.0.0-py3-none-any.whl\n",
      "Collecting numpy>=1.14\n",
      "  Using cached https://files.pythonhosted.org/packages/63/0c/0261693cc3ad8e2b66e66dc2d2676a2cc17d3efb1c58a70db73754320e47/numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting pbr>=0.11\n",
      "  Using cached https://files.pythonhosted.org/packages/7a/db/a968fd7beb9fe06901c1841cb25c9ccb666ca1b9a19b114d1bbedf1126fc/pbr-5.4.4-py2.py3-none-any.whl\n",
      "Collecting pyparsing>=2.1.4\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl\n",
      "Collecting rsa>=3.1.4\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.7\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.0.5\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/de/3a/83/77a1e18e1a8757186df834b86ce6800120ac9c79cd8ca4091b/grpc_google_iam_v1-0.12.3-cp37-none-any.whl\n",
      "Collecting google-api-core[grpc]<2.0.0dev,>=1.14.0\n",
      "  Using cached https://files.pythonhosted.org/packages/63/7e/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77/google_api_core-1.16.0-py2.py3-none-any.whl\n",
      "Collecting fasteners>=0.14\n",
      "  Using cached https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n",
      "Collecting google-resumable-media<0.5.0dev,>=0.3.1\n",
      "  Using cached https://files.pythonhosted.org/packages/96/d7/b29a41b01b854480891dfc408211ffb0cc7a2a3d5f15a3b6740ec18c845b/google_resumable_media-0.4.1-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706/googleapis_common_protos-1.51.0-cp37-none-any.whl\n",
      "Collecting google-auth<2.0dev,>=0.4.0\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl\n",
      "Collecting monotonic>=0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Running setup.py clean for future\n",
      "Failed to build future\n",
      "Installing collected packages: six, python-dateutil, urllib3, idna, chardet, certifi, requests, docopt, hdfs, fastavro, setuptools, protobuf, pymongo, numpy, pyarrow, grpcio, pbr, mock, pytz, future, dill, httplib2, PyYAML, pyparsing, pydot, pyasn1, rsa, pyasn1-modules, oauth2client, crcmod, avro-python3, cachetools, google-auth, googleapis-common-protos, google-api-core, google-cloud-core, grpc-google-iam-v1, google-cloud-bigtable, google-cloud-datastore, monotonic, fasteners, google-apitools, google-cloud-pubsub, google-resumable-media, google-cloud-bigquery, apache-beam\n",
      "    Running setup.py install for future: started\n",
      "    Running setup.py install for future: finished with status 'done'\n",
      "Successfully installed PyYAML-5.1.2 apache-beam-2.19.0 avro-python3-1.9.2.1 cachetools-3.1.1 certifi-2019.11.28 chardet-3.0.4 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-0.21.24 fasteners-0.15 future-0.18.2 google-api-core-1.16.0 google-apitools-0.5.28 google-auth-1.11.2 google-cloud-bigquery-1.17.1 google-cloud-bigtable-1.0.0 google-cloud-core-1.3.0 google-cloud-datastore-1.7.4 google-cloud-pubsub-1.0.2 google-resumable-media-0.4.1 googleapis-common-protos-1.51.0 grpc-google-iam-v1-0.12.3 grpcio-1.27.2 hdfs-2.5.8 httplib2-0.12.0 idna-2.9 mock-2.0.0 monotonic-1.5 numpy-1.18.1 oauth2client-3.0.0 pbr-5.4.4 protobuf-3.11.3 pyarrow-0.14.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydot-1.4.1 pymongo-3.10.1 pyparsing-2.4.6 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 rsa-4.0 setuptools-46.0.0 six-1.12.0 urllib3-1.25.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: astroid 2.3.1 has requirement wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 install --upgrade apache-beam[gcp]==2.16.0 six==1.12 --ignore-installed PyYAML==3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/mujahid7292/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc/wrapt-1.11.1-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting apache-beam[gcp]==2.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/54/6835fc8efeef0ff109a1f11452aa583c213cdde19e608ab6f555b51bf394/apache_beam-2.16.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/18/62/08/7b4aee4bd80bd969f9c9c653556b0c8732c9c1fbff18a2b26d/tensorflow_transform-0.15.0-cp37-none-any.whl\n",
      "Collecting six==1.12\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/03/05/65/bdc14f2c6e09e82ae3e0f13d021e1b6b2481437ea2f207df3f/PyYAML-3.12-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting pyarrow<0.15.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\"\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/ef/65cc820e4563c946592cb3d38f33bc342160943231ffae8a9550460f9bb7/pyarrow-0.14.1-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/48/f7/87/b932f09c6335dbcf45d916937105a372ab14f353a9ca431d7d/oauth2client-3.0.0-cp37-none-any.whl\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Using cached https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Collecting python-dateutil<3,>=2.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting pytz>=2018.3\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Collecting future<1.0.0,>=0.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/50/24/4d/4580ca4a299f1ad6fd63443e6e584cb21e9a07988e4aa8daac/crcmod-1.7-cp37-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/6d/41/4b/2b369d6e2b7eaebcdd423516d3fb659c7658c16a2be8fd04ec/httplib2-0.12.0-cp37-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/c9/de/a4/a91eec4eea652104d8c81b633f32ead5eb57d1b294eab24167/dill-0.3.0-cp37-none-any.whl\n",
      "Collecting protobuf<4,>=3.5.0.post1\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/f1/8dcd4219bbae8aa44fe8871a89f05eca2dca9c04f8dbfed8a82b7be97a88/protobuf-3.11.3-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/5a/d3/be/86620c9dd3fca68986c33b9c616510289fc0abb81ec9aa70bd/avro_python3-1.9.2.1-cp37-none-any.whl\n",
      "Collecting fastavro<0.22,>=0.21.4\n",
      "  Using cached https://files.pythonhosted.org/packages/af/fa/1c7b265aa44cf6089ce56a2702377a4994632016688b2b9ccde38a884024/fastavro-0.21.24-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70/hdfs-2.5.8-cp37-none-any.whl\n",
      "Collecting mock<3.0.0,>=1.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl\n",
      "Collecting grpcio<2,>=1.12.1\n",
      "  Using cached https://files.pythonhosted.org/packages/fb/00/997acb1c16f84e6d3ede511500f54e7b7a1fdfe7b4da5a5c2d07ad4e91f1/grpcio-1.27.2-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/e2/91a313e50adcf35182e260d65cf7ec60f6f0367abefc2fbab264e6f4544d/pymongo-3.10.1-cp37-cp37m-manylinux2014_x86_64.whl\n",
      "Collecting google-cloud-core<2,>=0.28.1; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\n",
      "Collecting google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/91/07a82945a7396ea34debafd476724bb5fc267c292790fdf2138c693f95c5/google_cloud_pubsub-1.0.2-py2.py3-none-any.whl\n",
      "Collecting google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/96/1b9cf1d43869c47a205aad411dac7c3040df6093d63c39273fa4d4c45da7/google_cloud_bigquery-1.17.1-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/d6/c2/92/837e8a4d649a209dff85b38d7fbb576b4b480738be70865f29/google_apitools-0.5.28-cp37-none-any.whl\n",
      "Collecting cachetools<4,>=3.1.0; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/d0/aa/29cbcf8cf7d08ce2d55b9dce858f7c632b434cb6451bed17cb4275804217/google_cloud_datastore-1.7.4-py2.py3-none-any.whl\n",
      "Collecting google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"\n",
      "  Using cached https://files.pythonhosted.org/packages/95/af/0ef7d097a1d5ad0c843867600e86de915e8ab8864740f49a4636cfb51af6/google_cloud_bigtable-1.0.0-py2.py3-none-any.whl\n",
      "Collecting tfx-bsl<0.16,>=0.15\n",
      "  Using cached https://files.pythonhosted.org/packages/ed/fc/e016ef9e90c035cfba25d0c9d16f1faa11145a87e18ae7bc9560d20881dc/tfx_bsl-0.15.3-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Collecting tensorflow<2.2,>=1.15\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/56/0dbdae2a3c527a119bec0d5cf441655fe030ce1daa6fa6b9542f7dbd8664/tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc/absl_py-0.8.1-cp37-none-any.whl\n",
      "Collecting tensorflow-metadata<0.16,>=0.15\n",
      "  Using cached https://files.pythonhosted.org/packages/3b/0c/afb81ea6998f6e26521671585d1cd9d3f7945a8b9834764e91757453dc25/tensorflow_metadata-0.15.2-py2.py3-none-any.whl\n",
      "Collecting numpy<2,>=1.16\n",
      "  Using cached https://files.pythonhosted.org/packages/63/0c/0261693cc3ad8e2b66e66dc2d2676a2cc17d3efb1c58a70db73754320e47/numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting rsa>=3.1.4\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.0.5\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.7\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Collecting pyparsing>=2.1.4\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl\n",
      "Collecting setuptools\n",
      "  Using cached https://files.pythonhosted.org/packages/70/b8/b23170ddda9f07c3444d49accde49f2b92f97bb2f2ebc312618ef12e4bd6/setuptools-46.0.0-py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e/docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting requests>=2.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
      "Collecting pbr>=0.11\n",
      "  Using cached https://files.pythonhosted.org/packages/7a/db/a968fd7beb9fe06901c1841cb25c9ccb666ca1b9a19b114d1bbedf1126fc/pbr-5.4.4-py2.py3-none-any.whl\n",
      "Collecting google-api-core<2.0.0dev,>=1.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/63/7e/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77/google_api_core-1.16.0-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/de/3a/83/77a1e18e1a8757186df834b86ce6800120ac9c79cd8ca4091b/grpc_google_iam_v1-0.12.3-cp37-none-any.whl\n",
      "Collecting google-resumable-media<0.5.0dev,>=0.3.1\n",
      "  Using cached https://files.pythonhosted.org/packages/96/d7/b29a41b01b854480891dfc408211ffb0cc7a2a3d5f15a3b6740ec18c845b/google_resumable_media-0.4.1-py2.py3-none-any.whl\n",
      "Collecting fasteners>=0.14\n",
      "  Using cached https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n",
      "Collecting tensorflow-serving-api<3,>=1.15\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/0b/be364dc6271a633629174fc02d36b2837cc802250d6a0afd96f8e7f2fae6/tensorflow_serving_api-2.1.0-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/d7/69/b4/3200b95828d1f0ddb3cb5699083717f4fdbd9b4223d0644c57/psutil-5.7.0-cp37-cp37m-linux_x86_64.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp37-none-any.whl\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/82/c1fe128f3526b128cfd185580ba40d01371c5d299fcf7f77968e22dfcc2e/scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp37-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/49/2233e63052d5686c72131b579837ddfb98ba9dd0b92bb91efcb441ada8ce/opt_einsum-3.2.0-py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl\n",
      "Collecting wheel>=0.26; python_version >= \"3\"\n",
      "  Using cached https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Processing /home/mujahid7292/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706/googleapis_common_protos-1.51.0-cp37-none-any.whl\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Collecting google-auth<2.0dev,>=0.4.0\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl\n",
      "Collecting monotonic>=0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
      "Collecting h5py\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Running setup.py clean for future\n",
      "Failed to build future\n",
      "Installing collected packages: wrapt, numpy, six, pyarrow, pyasn1, rsa, pyasn1-modules, httplib2, oauth2client, pyparsing, pydot, python-dateutil, pytz, PyYAML, future, crcmod, dill, setuptools, protobuf, avro-python3, fastavro, docopt, idna, chardet, urllib3, certifi, requests, hdfs, pbr, mock, grpcio, pymongo, cachetools, google-auth, googleapis-common-protos, google-api-core, google-cloud-core, grpc-google-iam-v1, google-cloud-pubsub, google-resumable-media, google-cloud-bigquery, monotonic, fasteners, google-apitools, google-cloud-datastore, google-cloud-bigtable, apache-beam, gast, scipy, astor, termcolor, opt-einsum, keras-preprocessing, tensorflow-estimator, h5py, keras-applications, werkzeug, oauthlib, requests-oauthlib, google-auth-oauthlib, absl-py, wheel, markdown, tensorboard, google-pasta, tensorflow, tensorflow-serving-api, psutil, tensorflow-metadata, tfx-bsl, tensorflow-transform\n",
      "    Running setup.py install for future: started\n",
      "    Running setup.py install for future: finished with status 'done'\n",
      "Successfully installed PyYAML-5.1.2 absl-py-0.8.1 apache-beam-2.19.0 astor-0.8.1 avro-python3-1.9.2.1 cachetools-3.1.1 certifi-2019.11.28 chardet-3.0.4 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-0.21.24 fasteners-0.15 future-0.18.2 gast-0.2.2 google-api-core-1.16.0 google-apitools-0.5.28 google-auth-1.11.2 google-auth-oauthlib-0.4.1 google-cloud-bigquery-1.17.1 google-cloud-bigtable-1.0.0 google-cloud-core-1.3.0 google-cloud-datastore-1.7.4 google-cloud-pubsub-1.0.2 google-pasta-0.1.8 google-resumable-media-0.4.1 googleapis-common-protos-1.51.0 grpc-google-iam-v1-0.12.3 grpcio-1.27.2 h5py-2.10.0 hdfs-2.5.8 httplib2-0.12.0 idna-2.9 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 mock-2.0.0 monotonic-1.5 numpy-1.18.1 oauth2client-3.0.0 oauthlib-3.1.0 opt-einsum-3.2.0 pbr-5.4.4 protobuf-3.11.3 psutil-5.7.0 pyarrow-0.14.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydot-1.4.1 pymongo-3.10.1 pyparsing-2.4.6 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 setuptools-46.0.0 six-1.12.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tensorflow-metadata-0.15.2 tensorflow-serving-api-2.1.0 tensorflow-transform-0.15.0 termcolor-1.1.0 tfx-bsl-0.15.3 urllib3-1.25.8 werkzeug-1.0.0 wheel-0.34.2 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "pip3 install wrapt==1.11.1 apache-beam[gcp]==2.16.0 tensorflow_transform==0.15.0 six==1.12 --ignore-installed PyYAML==3.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Restart the kernel</b> after you do a pip install (click on the reload button above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apache-beam==2.19.0\n",
      "tensorflow==2.1.0\n",
      "tensorflow-datasets==1.2.0\n",
      "tensorflow-estimator==2.1.0\n",
      "tensorflow-metadata==0.15.2\n",
      "tensorflow-serving-api==2.1.0\n",
      "tensorflow-transform==0.15.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep -e 'flow\\|beam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'ml-practice-260405'\n",
    "BUCKET = 'buck_ml-practice-260405'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/media/mujahid7292/Data/GOOGLE_SERVICE_ACCOUNT_SANDCORP2014/ML-Practice-0f3bae5b7b0d.json\"\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create GCS bucket if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://buck_ml-practice-260405/...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input source: BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from BigQuery but defer filtering etc. to Beam. Note that the `dayofweek` column is now string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "def create_query(phase, EVERY_N):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        phase: 1=Train and 2=valid\n",
    "    \"\"\"\n",
    "    base_query = \"\"\"\n",
    "    WITH daynames AS\n",
    "        (SELECT ['Sun', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat'] AS daysofweek)\n",
    "    SELECT\n",
    "        (tolls_amount + fare_amount) AS fare_amount,\n",
    "        daysofweek[ORDINAL(EXTRACT(DAYOFWEEK FROM pickup_datetime))] AS dayofweek,\n",
    "        EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "        pickup_longitude AS pickuplon,\n",
    "        pickup_latitude AS pickuplat,\n",
    "        dropoff_longitude AS dropofflon,\n",
    "        dropoff_latitude AS dropofflat,\n",
    "        passenger_count AS passengers,\n",
    "        'notneeded' AS key\n",
    "    FROM\n",
    "        `nyc-tlc.yellow.trips`, daynames\n",
    "    WHERE\n",
    "        trip_distance > 0\n",
    "        AND fare_amount > 0\n",
    "    \"\"\"\n",
    "    if EVERY_N == None:\n",
    "        if phase < 2:\n",
    "          # training\n",
    "          query = \"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING), 4)) < 2\".format(base_query)\n",
    "        else:\n",
    "          query = \"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING), 4)) = {1}\".format(base_query, phase)\n",
    "    else:\n",
    "      query = \"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)), {1})) = {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "      return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = create_query(2, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.988567</td>\n",
       "      <td>40.731555</td>\n",
       "      <td>-73.970687</td>\n",
       "      <td>40.752457</td>\n",
       "      <td>1</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.954310</td>\n",
       "      <td>40.765680</td>\n",
       "      <td>-73.978150</td>\n",
       "      <td>40.741740</td>\n",
       "      <td>1</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.984242</td>\n",
       "      <td>40.729010</td>\n",
       "      <td>-73.955670</td>\n",
       "      <td>40.775377</td>\n",
       "      <td>5</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19.5</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.983860</td>\n",
       "      <td>40.759777</td>\n",
       "      <td>-73.906987</td>\n",
       "      <td>40.744350</td>\n",
       "      <td>5</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.956865</td>\n",
       "      <td>40.770845</td>\n",
       "      <td>-73.963595</td>\n",
       "      <td>40.774335</td>\n",
       "      <td>1</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount dayofweek  hourofday  pickuplon  pickuplat  dropofflon  \\\n",
       "0         10.0       Mon          0 -73.988567  40.731555  -73.970687   \n",
       "1          9.5       Sun          0 -73.954310  40.765680  -73.978150   \n",
       "2         14.0       Sun          0 -73.984242  40.729010  -73.955670   \n",
       "3         19.5       Sun          0 -73.983860  40.759777  -73.906987   \n",
       "4          4.5       Mon          0 -73.956865  40.770845  -73.963595   \n",
       "\n",
       "   dropofflat  passengers        key  \n",
       "0   40.752457           1  notneeded  \n",
       "1   40.741740           1  notneeded  \n",
       "2   40.775377           5  notneeded  \n",
       "3   40.744350           5  notneeded  \n",
       "4   40.774335           1  notneeded  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>11.242599</td>\n",
       "      <td>13.244075</td>\n",
       "      <td>-72.576852</td>\n",
       "      <td>39.973146</td>\n",
       "      <td>-72.748974</td>\n",
       "      <td>40.006091</td>\n",
       "      <td>1.722118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.447462</td>\n",
       "      <td>6.548354</td>\n",
       "      <td>10.133452</td>\n",
       "      <td>5.777329</td>\n",
       "      <td>12.981577</td>\n",
       "      <td>5.664887</td>\n",
       "      <td>1.351062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-78.133333</td>\n",
       "      <td>-73.991278</td>\n",
       "      <td>-751.400000</td>\n",
       "      <td>-73.977970</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-73.991849</td>\n",
       "      <td>40.734954</td>\n",
       "      <td>-73.991236</td>\n",
       "      <td>40.734008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-73.981824</td>\n",
       "      <td>40.752640</td>\n",
       "      <td>-73.980164</td>\n",
       "      <td>40.753427</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-73.967418</td>\n",
       "      <td>40.766700</td>\n",
       "      <td>-73.964153</td>\n",
       "      <td>40.767832</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>40.806487</td>\n",
       "      <td>41.366138</td>\n",
       "      <td>40.785400</td>\n",
       "      <td>41.366138</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount     hourofday     pickuplon     pickuplat    dropofflon  \\\n",
       "count  11181.000000  11181.000000  11181.000000  11181.000000  11181.000000   \n",
       "mean      11.242599     13.244075    -72.576852     39.973146    -72.748974   \n",
       "std        9.447462      6.548354     10.133452      5.777329     12.981577   \n",
       "min        2.500000      0.000000    -78.133333    -73.991278   -751.400000   \n",
       "25%        6.000000      9.000000    -73.991849     40.734954    -73.991236   \n",
       "50%        8.500000     14.000000    -73.981824     40.752640    -73.980164   \n",
       "75%       12.500000     19.000000    -73.967418     40.766700    -73.964153   \n",
       "max      143.000000     23.000000     40.806487     41.366138     40.785400   \n",
       "\n",
       "         dropofflat    passengers  \n",
       "count  11181.000000  11181.000000  \n",
       "mean      40.006091      1.722118  \n",
       "std        5.664887      1.351062  \n",
       "min      -73.977970      0.000000  \n",
       "25%       40.734008      1.000000  \n",
       "50%       40.753427      1.000000  \n",
       "75%       40.767832      2.000000  \n",
       "max       41.366138      6.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = bigquery.Client().query(query).to_dataframe()\n",
    "display(df_valid.head())\n",
    "df_valid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ML dataset using tf.transform and Dataflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Cloud Dataflow to read in the BigQuery data and write it out as CSV files. Along the way, let's use tf.transform to do scaling and transforming. Using tf.transform allows us to save the metadata to ensure that the appropriate transformations get carried out during prediction as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "tensorflow-transform==0.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test <b>`transformdata`</b> is type PClollection. Test if= is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(inputs):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        inputs: This is a dictionary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pickup_longitude = inputs['pickuplon']\n",
    "        pickup_latitude = inputs['pickuplat']\n",
    "        dropoff_longitude = inputs['dropofflon']\n",
    "        dropoff_latitude = inputs['dropofflat']\n",
    "        hourofday = inputs['hourofday']\n",
    "        dayofweek = inputs['dayofweek']\n",
    "        passenger_counts = inputs['passengers']\n",
    "        fare_amount = inputs['fare_amount']\n",
    "        return (fare_amount >= 2.5 and pickup_longitude > -78 and pickup_longitude < -70\\\n",
    "               and dropoff_longitude > -78 and dropoff_longitude < -70 and \\\n",
    "               pickup_latitude > 37 and pickup_latitude < 45 and \\\n",
    "               dropoff_latitude > 37 and dropoff_latitude < 45 and \\\n",
    "               passenger_counts > 0)\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tft(inputs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_transform as ttf\n",
    "    \n",
    "    print(inputs)\n",
    "    # Create a new dictionary\n",
    "    result = {}\n",
    "    result['fare_amount'] = tf.identity(inputs['fare_amount']) # Pass through\n",
    "    result['dayofweek'] = tft.string_to_int(inputs['dayofweek']) # Builds a vocabulary\n",
    "    result['hourofday'] = tf.identity(inputs['hourofday']) # Pass through\n",
    "    result['pickuplon'] = (tft.scale_to_0_1(inputs['pickuplon'])) # Scaling numeric value\n",
    "    result['pickuplat'] = (tft.scale_to_0_1(inputs['pickuplat'])) # Scaling numeric value\n",
    "    result['dropofflon'] = (tft.scale_to_0_1(inpuits['dropofflon'])) # Scaling numeric value\n",
    "    result['dropofflat'] = (tft.scale_to_0_1(inputs['dropofflat'])) # Scaling numeric value\n",
    "    result['passengers'] = tf.cast(inputs['passengers'], tf.float32) # Cast int to float\n",
    "    result['key'] = tf.as_string(tf.ones_like(inputs['passengers'])) # Arbitary TF function\n",
    "    # Engineered Features\n",
    "    latdiff = inputs['pickuplat'] - inputs['dropofflat']\n",
    "    londiff = inputs['pickuplon'] - inputs['dropofflat']\n",
    "    result['latdiff'] = tft.scale_to_0_1(latdiff) # Scaling numeric value\n",
    "    result['londiff'] = tft.scale_to_0_1(londiff) # Scaling numeric value\n",
    "    dist = tf.sqrt(latdiff * latdiff + londiff * londiff)\n",
    "    result['euclidean'] = tft.scale_0_1(dist) # Scaling numeric value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(in_test_mode):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import os.path\n",
    "    import tempfile\n",
    "    import datetime\n",
    "    import apache_beam as beam\n",
    "    from apache_beam.io import tfrecordio\n",
    "    from tensorflow_transform.coders import example_proto_coder\n",
    "    from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "    from tensorflow_transform.tf_metadata import dataset_schema\n",
    "    from tensorflow_transform.beam import impl as beam_impl\n",
    "    from tensorflow_transform.beam import tft_beam_io\n",
    "    from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "    \n",
    "    job_name = 'preprocess-taxi-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    \n",
    "    if in_test_mode:\n",
    "        import shutil\n",
    "        print ('Launching local job.......hang on')\n",
    "        OUTPUT_DIR = './preproc_tft'\n",
    "        shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "        EVERY_N = 100000 # 1 Lac\n",
    "    else:\n",
    "        print('Launching dataflow job {}......hang on'.format(job_name))\n",
    "        OUTPUT_DIR = 'gs://{0}/taxifare/preproc_tft/'.format(BUCKET)\n",
    "        import subprocess\n",
    "        # Delete Out put directory if exist\n",
    "        subprocess.call(' gsutil rm -r {}'.format(OUTPUT_DIR).spilt())\n",
    "        EVERY_N = 10000 # 10 Thousands\n",
    "    \n",
    "    # Create a dictionary called options, Which will be used to create\n",
    "    # beam PipelineOptions object\n",
    "    options = {\n",
    "        'staging_location':os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "        'temp_location':os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "        'job_name':job_name,\n",
    "        'project':PROJECT,\n",
    "        'max_num_workers':6,\n",
    "        'teardown_policy':'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session':True,\n",
    "        'requirements_file':'requirements.txt'\n",
    "    }\n",
    "    \n",
    "    # create a PipelineOptions object\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    \n",
    "    # Select Runner\n",
    "    if in_test_mode:\n",
    "        RUNNER = 'DirectRunner'\n",
    "    else:\n",
    "        RUNNER = 'DataflowRunner'\n",
    "        \n",
    "    # Set up raw data metadata\n",
    "    # Create a dictionary by the name `raw_data_schema`. This dictionary will\n",
    "    # be used to create `dataset_metadata` object.\n",
    "    raw_data_schema = {\n",
    "        colname : dataset_schema.ColumnSchema(\n",
    "            tf.string,\n",
    "            [],\n",
    "            dataset_schema.FixedColumnRepresentation()\n",
    "        ) for colname in 'dayofweek,key'.split(',')\n",
    "    }\n",
    "    \n",
    "    # update `raw_data_schema` dictionary with all the float type input features\n",
    "    raw_data_schema.update({\n",
    "        colname : dataset_schema.ColumnSchema(\n",
    "            tf.float32,\n",
    "            [],\n",
    "            dataset_schema.FixedColumnRepresentation()\n",
    "        ) for colname in 'fare_amount,pickuplon,pickuplat,dropofflon,dropofflat'.split(',')\n",
    "    })\n",
    "    \n",
    "    # update `raw_data_schema` dictionary with all the int type input features \n",
    "    raw_data_schema.update({\n",
    "        colname : dataset_schema.ColumnSchema(\n",
    "            tf.int64,\n",
    "            [],\n",
    "            dataset_schema.FixedColumnRepresentation()\n",
    "        ) for colname in 'hourofday,passengers'.split(',')\n",
    "    })\n",
    "    \n",
    "    # Create a `dataset_metadata` object and name this object as 'raw_data_metadata'\n",
    "    raw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.Schema(raw_data_schema))\n",
    "    \n",
    "    # Run Beam Pipeline\n",
    "    with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "        with beam_impl.Context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
