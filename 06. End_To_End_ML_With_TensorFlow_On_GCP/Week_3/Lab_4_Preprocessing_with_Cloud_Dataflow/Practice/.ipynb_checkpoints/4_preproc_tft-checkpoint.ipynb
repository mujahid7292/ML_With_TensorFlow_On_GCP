{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Preprocessing using tf.transform and Dataflow </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating datasets for Machine Learning using tf.transform and Dataflow\n",
    "</ol>\n",
    "<p>\n",
    "While Pandas is fine for experimenting, for operationalization of your workflow, it is better to do preprocessing in Apache Beam. This will also help if you need to preprocess data in flight, since Apache Beam also allows for streaming."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Beam only works in Python 2 at the moment, so we're going to switch to the Python 2 kernel. In the above menu, click the dropdown arrow and select `python2`. ![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then activate a Python 2 environment and install Apache Beam. Only specific combinations of TensorFlow/Beam are supported by tf.transform. So make sure to get a combo that is.\n",
    "* TFT 0.8.0\n",
    "* TF 1.8 or higher\n",
    "* Apache Beam [GCP] 2.5.0 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  /home/mujahid7292/anaconda3\n",
      "py2env                   /home/mujahid7292/anaconda3/envs/py2env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: A conda environment already exists at '/home/mujahid7292/anaconda3/envs/py2env'\n",
      "Remove existing environment (y/[n])? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaSystemExit: Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda create --name py2env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "conda update -y -n base -c defaults conda\n",
    "source activate py2env\n",
    "pip uninstall -y google-cloud-dataflow\n",
    "conda install -y pytz\n",
    "pip install apache-beam[gcp]==2.20.0\n",
    "pip install apache-beam[gcp] tensorflow_transform==0.15.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip freeze | grep -e 'flow\\|beam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to restart your kernel to register the new installs running the below cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "ACCOUNT = 'student-02-b97575b6b46d@qwiklabs.net'\n",
    "SAC = 'qwik-jupyter-notebook-sac-f'\n",
    "SAC_KEY_DESTINATION = '/media/mujahid7292/Data/Gcloud_Tem_SAC'\n",
    "BUCKET = 'bucket-qwiklabs-gcp-02-3fc87b630759'\n",
    "PROJECT = 'qwiklabs-gcp-02-3fc87b630759'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ACCOUNT'] = ACCOUNT\n",
    "os.environ['SAC'] = SAC\n",
    "os.environ['SAC_KEY_DESTINATION'] = SAC_KEY_DESTINATION\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud config set project $PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Google Application Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='{}/{}.json'.format(SAC_KEY_DESTINATION,SAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Whether Google Application Credential Was Set Successfully Outside Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_APPLICATION_CREDENTIALS=/media/mujahid7292/Data/Gcloud_Tem_SAC/jupyter-notebook-sac-f.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set | grep GOOGLE_APPLICATION_CREDENTIALS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Save the query from earlier </h2>\n",
    "\n",
    "The data is natality data (record of births in the US). My goal is to predict the baby's weight given a number of factors about the pregnancy and the baby's mother.  Later, we will want to split the data into training and eval datasets. The hash of the year-month will be used for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "SELECT\n",
    "  weight_pounds,\n",
    "  is_male,\n",
    "  mother_age,\n",
    "  mother_race,\n",
    "  plurality,\n",
    "  gestation_weeks,\n",
    "  mother_married,\n",
    "  ever_born,\n",
    "  cigarette_use,\n",
    "  alcohol_use,\n",
    "  FARM_FINGERPRINT(CONCAT(CAST(YEAR AS STRING), CAST(month AS STRING))) AS hashmonth\n",
    "FROM\n",
    "  publicdata.samples.natality\n",
    "WHERE year > 2000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>mother_race</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>mother_married</th>\n",
       "      <th>ever_born</th>\n",
       "      <th>cigarette_use</th>\n",
       "      <th>alcohol_use</th>\n",
       "      <th>hashmonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.818490</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>-1403073183891835564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.141671</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>8904940584331855459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.948072</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7108882242435606404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.838332</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3408502330831153141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.259415</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1088037545023002395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  mother_race  plurality  \\\n",
       "0       8.818490    False          17            1          1   \n",
       "1       8.141671    False          29            1          1   \n",
       "2       5.948072     True          38            2          1   \n",
       "3       8.838332     True          27            1          1   \n",
       "4       9.259415     True          28            1          1   \n",
       "\n",
       "   gestation_weeks  mother_married  ever_born cigarette_use alcohol_use  \\\n",
       "0               42           False          1          None       False   \n",
       "1               38            True          2          None       False   \n",
       "2               38           False          3          None       False   \n",
       "3               39            True          4          None       False   \n",
       "4               38           False          2          None       False   \n",
       "\n",
       "             hashmonth  \n",
       "0 -1403073183891835564  \n",
       "1  8904940584331855459  \n",
       "2  7108882242435606404  \n",
       "3  3408502330831153141  \n",
       "4  1088037545023002395  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call BigQuery and examine in dataframe\n",
    "from google.cloud import bigquery\n",
    "df = bigquery.Client().query(query + \" LIMIT 100\").to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create ML dataset using tf.transform and Dataflow </h2>\n",
    "<p>\n",
    "Let's use Cloud Dataflow to read in the BigQuery data and write it out as CSV files. Along the way, let's use tf.transform to do scaling and transforming. Using tf.transform allows us to save the metadata to ensure that the appropriate transformations get carried out during prediction as well.\n",
    "<p>\n",
    "Note that after you launch this, the notebook won't show you progress. Go to the GCP webconsole to the Dataflow section and monitor the running job. It took about <b>30 minutes</b> for me. If you wish to continue without doing this step, you can copy my preprocessed output:\n",
    "<pre>\n",
    "gsutil -m cp -r gs://cloud-training-demos/babyweight/preproc_tft gs://your-bucket/\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "tensorflow-transform==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0427 11:13:24.262236 140299699287872 impl.py:425] Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "W0427 11:13:24.263914 140299699287872 impl.py:425] Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "W0427 11:13:24.332362 140299699287872 meta_graph.py:436] Issue encountered when serializing tft_analyzer_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "W0427 11:13:24.332888 140299699287872 meta_graph.py:436] Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching local job ... hang on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0427 11:13:24.812964 140299699287872 meta_graph.py:436] Issue encountered when serializing tft_analyzer_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "W0427 11:13:24.813534 140299699287872 meta_graph.py:436] Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "W0427 11:13:24.975245 140299699287872 impl.py:425] Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "W0427 11:13:25.082797 140299699287872 impl.py:425] Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "W0427 11:13:25.083358 140299699287872 interactive_utils.py:85] Failed to alter the label of a transform with the ipython prompt metadata. Cannot figure out the pipeline that the given pvalueish ((<PCollection[eval_cleanup.None] at 0x7f997019d320>, {'_schema': feature {\n",
      "  name: \"alcohol_use\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"cigarette_use\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"gestation_weeks\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"is_male\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"key\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mother_age\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mother_married\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mother_race\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"plurality\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"weight_pounds\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "}), (<PCollection[AnalyzeAndTransformDataset/AnalyzeDataset/CreateSavedModel/BindTensors/ReplaceWithConstants.None] at 0x7f99700af5f8>, BeamDatasetMetadata(dataset_metadata={'_schema': feature {\n",
      "  name: \"alcohol_use\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"cigarette_use\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"gestation_weeks\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"gestation_weeks_centered\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"is_male\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"key\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mother_age\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mother_age_tft\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mother_married\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mother_race\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"mother_race_tft\"\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    is_categorical: true\n",
      "  }\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"plurality\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"weight_pounds\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "}, deferred_metadata=<PCollection[AnalyzeAndTransformDataset/AnalyzeDataset/ComputeDeferredMetadata.None] at 0x7f99702fc6a0>))) belongs to. Thus noop.\n",
      "W0427 11:13:29.344271 140297036093184 bigquery_tools.py:617] Dataset ml-practice-260405:temp_dataset_66dcc8f3cfbb474b9295aff0fdd40928 does not exist so we will create it as temporary with location=US\n",
      "W0427 11:13:37.283860 140297036093184 bigquery_tools.py:617] Dataset ml-practice-260405:temp_dataset_b2d4472a8d804b99bb1e064c2afda8ba does not exist so we will create it as temporary with location=US\n",
      "W0427 11:13:42.354808 140297036093184 ops.py:6451] Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "W0427 11:13:42.399029 140297036093184 ops.py:6451] Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "W0427 11:13:42.450843 140297036093184 ops.py:6451] Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "W0427 11:13:47.565106 140297036093184 bigquery_tools.py:617] Dataset ml-practice-260405:temp_dataset_4b5b81104c0846d7b5e326ef160153d4 does not exist so we will create it as temporary with location=US\n",
      "W0427 11:13:54.349103 140297036093184 bigquery_tools.py:617] Dataset ml-practice-260405:temp_dataset_d20890e971314944bcbde85af48274a8 does not exist so we will create it as temporary with location=US\n",
      "W0427 11:14:00.969402 140297036093184 filebasedsink.py:227] Deleting 1 existing files in target path matching: \n",
      "W0427 11:14:01.230298 140297036093184 ops.py:6451] Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "W0427 11:14:01.275686 140297036093184 ops.py:6451] Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "W0427 11:14:01.336725 140297036093184 ops.py:6451] Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "E0427 11:14:01.434914 140297036093184 executor.py:389] Exception at bundle <apache_beam.runners.direct.bundle_factory._Bundle object at 0x7f9978266388>, due to an exception.\n",
      " Traceback (most recent call last):\n",
      "  File \"apache_beam/runners/common.py\", line 950, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 720, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 798, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1444, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\", line 104, in publish_outputs\n",
      "    tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 521, in rename_v2\n",
      "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\", line 382, in call\n",
      "    finish_state)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\", line 420, in attempt_call\n",
      "    evaluator.process_element(value)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/transform_evaluator.py\", line 794, in process_element\n",
      "    self.runner.process(element)\n",
      "  File \"apache_beam/runners/common.py\", line 947, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 952, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1028, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/future/utils/__init__.py\", line 446, in raise_with_traceback\n",
      "    raise exc.with_traceback(traceback)\n",
      "  File \"apache_beam/runners/common.py\", line 950, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 720, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 798, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1444, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\", line 104, in publish_outputs\n",
      "    tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 521, in rename_v2\n",
      "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
      "RuntimeError: tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty [while running 'WriteTransformFn/PublishMetadataAndTransformFn']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0427 11:14:01.441555 140297036093184 executor.py:389] Exception at bundle <apache_beam.runners.direct.bundle_factory._Bundle object at 0x7f9978266388>, due to an exception.\n",
      " Traceback (most recent call last):\n",
      "  File \"apache_beam/runners/common.py\", line 950, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 720, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 798, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1444, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\", line 104, in publish_outputs\n",
      "    tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 521, in rename_v2\n",
      "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\", line 382, in call\n",
      "    finish_state)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\", line 420, in attempt_call\n",
      "    evaluator.process_element(value)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/transform_evaluator.py\", line 794, in process_element\n",
      "    self.runner.process(element)\n",
      "  File \"apache_beam/runners/common.py\", line 947, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 952, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1028, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/future/utils/__init__.py\", line 446, in raise_with_traceback\n",
      "    raise exc.with_traceback(traceback)\n",
      "  File \"apache_beam/runners/common.py\", line 950, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 720, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 798, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1444, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\", line 104, in publish_outputs\n",
      "    tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 521, in rename_v2\n",
      "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
      "RuntimeError: tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty [while running 'WriteTransformFn/PublishMetadataAndTransformFn']\n",
      "\n",
      "E0427 11:14:01.450466 140297036093184 executor.py:389] Exception at bundle <apache_beam.runners.direct.bundle_factory._Bundle object at 0x7f9978266388>, due to an exception.\n",
      " Traceback (most recent call last):\n",
      "  File \"apache_beam/runners/common.py\", line 950, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 720, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 798, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1444, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\", line 104, in publish_outputs\n",
      "    tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 521, in rename_v2\n",
      "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\", line 382, in call\n",
      "    finish_state)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\", line 420, in attempt_call\n",
      "    evaluator.process_element(value)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/transform_evaluator.py\", line 794, in process_element\n",
      "    self.runner.process(element)\n",
      "  File \"apache_beam/runners/common.py\", line 947, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 952, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1028, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/future/utils/__init__.py\", line 446, in raise_with_traceback\n",
      "    raise exc.with_traceback(traceback)\n",
      "  File \"apache_beam/runners/common.py\", line 950, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 720, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 798, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1444, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\", line 104, in publish_outputs\n",
      "    tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 521, in rename_v2\n",
      "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
      "RuntimeError: tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty [while running 'WriteTransformFn/PublishMetadataAndTransformFn']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0427 11:14:01.456236 140297036093184 executor.py:389] Exception at bundle <apache_beam.runners.direct.bundle_factory._Bundle object at 0x7f9978266388>, due to an exception.\n",
      " Traceback (most recent call last):\n",
      "  File \"apache_beam/runners/common.py\", line 950, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 720, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 798, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1444, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\", line 104, in publish_outputs\n",
      "    tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 521, in rename_v2\n",
      "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\", line 382, in call\n",
      "    finish_state)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\", line 420, in attempt_call\n",
      "    evaluator.process_element(value)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/transform_evaluator.py\", line 794, in process_element\n",
      "    self.runner.process(element)\n",
      "  File \"apache_beam/runners/common.py\", line 947, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 952, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1028, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/future/utils/__init__.py\", line 446, in raise_with_traceback\n",
      "    raise exc.with_traceback(traceback)\n",
      "  File \"apache_beam/runners/common.py\", line 950, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 720, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 798, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1444, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\", line 104, in publish_outputs\n",
      "    tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 521, in rename_v2\n",
      "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
      "RuntimeError: tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty [while running 'WriteTransformFn/PublishMetadataAndTransformFn']\n",
      "\n",
      "E0427 11:14:01.456750 140297036093184 executor.py:392] Giving up after 4 attempts.\n",
      "W0427 11:14:01.459316 140297036093184 executor.py:622] A task failed with exception: tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty [while running 'WriteTransformFn/PublishMetadataAndTransformFn']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty [while running 'WriteTransformFn/PublishMetadataAndTransformFn']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_fn_takes_side_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m     \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\u001b[0m in \u001b[0;36mpublish_outputs\u001b[0;34m(unused_element, metadata_source_path, transform_fn_source_path)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_source_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       tf.io.gfile.rename(\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrename_v2\u001b[0;34m(src, dst, overwrite)\u001b[0m\n\u001b[1;32m    520\u001b[0m   pywrap_tensorflow.RenameFile(\n\u001b[0;32m--> 521\u001b[0;31m       compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5f4b2eb97835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_test_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5f4b2eb97835>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(query, in_test_mode)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0min_test_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/direct_runner.py\u001b[0m in \u001b[0;36mwait_until_finish\u001b[0;34m(self, duration)\u001b[0m\n\u001b[1;32m    453\u001b[0m             'DirectRunner does not support duration argument.')\n\u001b[1;32m    454\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawait_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipelineState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\u001b[0m in \u001b[0;36mawait_completion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mawait_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawait_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\u001b[0m in \u001b[0;36mawait_completion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/future/utils/__init__.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEllipsis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, state_sampler)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mstart_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mprocess_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             finish_state)\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/executor.py\u001b[0m in \u001b[0;36mattempt_call\u001b[0;34m(self, metrics_container, side_input_values, start_state, process_state, finish_state)\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_bundle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_bundle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_elements_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m           \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfinish_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/direct/transform_evaluator.py\u001b[0m in \u001b[0;36mprocess_element\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinish_bundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/future/utils/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/runners/common.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         'Received %r instead.' % (fn))\n\u001b[1;32m   1443\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_fn_takes_side_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m     \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_transform/beam/tft_beam_io/transform_fn_io.py\u001b[0m in \u001b[0;36mpublish_outputs\u001b[0;34m(unused_element, metadata_source_path, transform_fn_source_path)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_source_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       tf.io.gfile.rename(\n\u001b[1;32m    106\u001b[0m           transform_fn_source_path, transform_fn_path, overwrite=True)\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_3/Lab_4_Preprocessing_with_Cloud_Dataflow/Practice/Venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrename_v2\u001b[0;34m(src, dst, overwrite)\u001b[0m\n\u001b[1;32m    519\u001b[0m   \"\"\"\n\u001b[1;32m    520\u001b[0m   pywrap_tensorflow.RenameFile(\n\u001b[0;32m--> 521\u001b[0;31m       compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tensorflow.python.framework.errors_impl.FailedPreconditionError: ./preproc_tft/metadata/transform_tmp/8286c940da5844a4b251073dbb3e5d6e; Directory not empty [while running 'WriteTransformFn/PublishMetadataAndTransformFn']"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import apache_beam as beam\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.beam import impl as beam_impl\n",
    "\n",
    "def preprocess_tft(inputs):\n",
    "    import copy\n",
    "    import numpy as np\n",
    "    def center(x):\n",
    "          return x - tft.mean(x)\n",
    "    result = copy.copy(inputs) # shallow copy\n",
    "    result['mother_age_tft'] = center(inputs['mother_age'])\n",
    "    result['gestation_weeks_centered'] = tft.scale_to_0_1(inputs['gestation_weeks'])\n",
    "    result['mother_race_tft'] = tft.string_to_int(inputs['mother_race'])\n",
    "    return result\n",
    "    #return inputs\n",
    "\n",
    "def cleanup(rowdict):\n",
    "    import copy, hashlib\n",
    "    CSV_COLUMNS = 'weight_pounds,is_male,mother_age,mother_race,plurality,gestation_weeks,mother_married,cigarette_use,alcohol_use'.split(',')\n",
    "    STR_COLUMNS = 'key,is_male,mother_race,mother_married,cigarette_use,alcohol_use'.split(',')\n",
    "    FLT_COLUMNS = 'weight_pounds,mother_age,plurality,gestation_weeks'.split(',')\n",
    "    \n",
    "    # add any missing columns, and correct the types\n",
    "    def tofloat(value, ifnot):\n",
    "      try:\n",
    "        return float(value)\n",
    "      except (ValueError, TypeError):\n",
    "        return ifnot\n",
    "\n",
    "    result = {\n",
    "      k : str(rowdict[k]) if k in rowdict else 'None' for k in STR_COLUMNS\n",
    "    }\n",
    "    result.update({\n",
    "        k : tofloat(rowdict[k], -99) if k in rowdict else -99 for k in FLT_COLUMNS\n",
    "      })\n",
    "    \n",
    "    # modify opaque numeric race code into human-readable data\n",
    "    races = dict(zip([1,2,3,4,5,6,7,18,28,39,48],\n",
    "                     ['White', 'Black', 'American Indian', 'Chinese', \n",
    "                      'Japanese', 'Hawaiian', 'Filipino',\n",
    "                      'Asian Indian', 'Korean', 'Samaon', 'Vietnamese'])) \n",
    "    if 'mother_race' in rowdict and rowdict['mother_race'] in races:\n",
    "      result['mother_race'] = races[rowdict['mother_race']]\n",
    "    else:\n",
    "      result['mother_race'] = 'Unknown'    \n",
    "    \n",
    "    # cleanup: write out only the data we that we want to train on\n",
    "    if result['weight_pounds'] > 0 and result['mother_age'] > 0 and result['gestation_weeks'] > 0 and result['plurality'] > 0:\n",
    "      data = ','.join([str(result[k]) for k in CSV_COLUMNS])\n",
    "      result['key'] = hashlib.sha224(data.encode('utf-8')).hexdigest()\n",
    "      yield result \n",
    "  \n",
    "def preprocess(query, in_test_mode):\n",
    "  import os\n",
    "  import os.path\n",
    "  import tempfile\n",
    "  import tensorflow as tf\n",
    "  from apache_beam.io import tfrecordio\n",
    "  from tensorflow_transform.coders import example_proto_coder\n",
    "  from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "  from tensorflow_transform.tf_metadata import dataset_schema\n",
    "  from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "\n",
    "  job_name = 'preprocess-babyweight-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "  if in_test_mode:\n",
    "    import shutil\n",
    "    print('Launching local job ... hang on')\n",
    "    OUTPUT_DIR = './preproc_tft'\n",
    "    shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "  else:\n",
    "    print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "    OUTPUT_DIR = 'gs://{0}/babyweight/preproc_tft/'.format(BUCKET)\n",
    "    import subprocess\n",
    "    subprocess.call('gsutil rm -r {}'.format(OUTPUT_DIR).split())\n",
    "    \n",
    "  options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': job_name,\n",
    "    'project': PROJECT,\n",
    "    'region': REGION,\n",
    "    'num_workers': 4,\n",
    "    'max_num_workers': 5,\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True,\n",
    "    'requirements_file': 'requirements.txt'\n",
    "  }\n",
    "  opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "  if in_test_mode:\n",
    "    RUNNER = 'DirectRunner'\n",
    "  else:\n",
    "    RUNNER = 'DataflowRunner'\n",
    "\n",
    "  # set up metadata  \n",
    "  raw_data_schema = {\n",
    "    colname : dataset_schema.ColumnSchema(tf.string, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in 'key,is_male,mother_race,mother_married,cigarette_use,alcohol_use'.split(',')\n",
    "  }\n",
    "  raw_data_schema.update({\n",
    "      colname : dataset_schema.ColumnSchema(tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in 'weight_pounds,mother_age,plurality,gestation_weeks'.split(',')\n",
    "    })\n",
    "  raw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.Schema(raw_data_schema))\n",
    "\n",
    "  def read_rawdata(p, step, test_mode):\n",
    "    if step == 'train':\n",
    "        selquery = 'SELECT * FROM ({}) WHERE ABS(MOD(hashmonth, 4)) < 3'.format(query)\n",
    "    else:\n",
    "        selquery = 'SELECT * FROM ({}) WHERE ABS(MOD(hashmonth, 4)) = 3'.format(query)\n",
    "    if in_test_mode:\n",
    "        selquery = selquery + ' LIMIT 100'\n",
    "    #print('Processing {} data from {}'.format(step, selquery))\n",
    "    return (p \n",
    "          | '{}_read'.format(step) >> beam.io.Read(beam.io.BigQuerySource(query=selquery, use_standard_sql=True))\n",
    "          | '{}_cleanup'.format(step) >> beam.FlatMap(cleanup)\n",
    "                   )\n",
    "  \n",
    "  # run Beam  \n",
    "  with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "    with beam_impl.Context(temp_dir=os.path.join(OUTPUT_DIR, 'tmp')):\n",
    "\n",
    "      # analyze and transform training       \n",
    "      raw_data = read_rawdata(p, 'train', in_test_mode)\n",
    "      raw_dataset = (raw_data, raw_data_metadata)\n",
    "      transformed_dataset, transform_fn = (\n",
    "          raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocess_tft))\n",
    "      transformed_data, transformed_metadata = transformed_dataset\n",
    "      _ = transformed_data | 'WriteTrainData' >> tfrecordio.WriteToTFRecord(\n",
    "          os.path.join(OUTPUT_DIR, 'train'),\n",
    "          coder=example_proto_coder.ExampleProtoCoder(\n",
    "              transformed_metadata.schema))\n",
    "      \n",
    "      # transform eval data\n",
    "      raw_test_data = read_rawdata(p, 'eval', in_test_mode)\n",
    "      raw_test_dataset = (raw_test_data, raw_data_metadata)\n",
    "      transformed_test_dataset = (\n",
    "          (raw_test_dataset, transform_fn) | beam_impl.TransformDataset())\n",
    "      transformed_test_data, _ = transformed_test_dataset\n",
    "      _ = transformed_test_data | 'WriteTestData' >> tfrecordio.WriteToTFRecord(\n",
    "          os.path.join(OUTPUT_DIR, 'eval'),\n",
    "          coder=example_proto_coder.ExampleProtoCoder(\n",
    "              transformed_metadata.schema))\n",
    "      _ = (transform_fn\n",
    "           | 'WriteTransformFn' >>\n",
    "           transform_fn_io.WriteTransformFn(os.path.join(OUTPUT_DIR, 'metadata')))\n",
    "\n",
    "  job = p.run()\n",
    "  if in_test_mode:\n",
    "    job.wait_until_finish()\n",
    "    print(\"Done!\")\n",
    "  \n",
    "preprocess(query, in_test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/babyweight/preproc_tft/*-00000*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
