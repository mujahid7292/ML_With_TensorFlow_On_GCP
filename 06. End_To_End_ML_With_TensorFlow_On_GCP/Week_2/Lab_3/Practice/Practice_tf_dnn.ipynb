{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable Virtual Environment For This Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will go to the location of the directory, where we will create our virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ cd /media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_2/Lab_3/Practice`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deactivate conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ conda deactivate`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate newly created virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ source Venv/bin/activate`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook <a href=\"https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/3_tensorflow_dnn.ipynb\">Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary import of python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_2/Lab_3/Practice/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_2/Lab_3/Practice/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_2/Lab_3/Practice/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_2/Lab_3/Practice/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_2/Lab_3/Practice/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/06. End_To_End_ML_With_TensorFlow_On_GCP/Week_2/Lab_3/Practice/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard module is not an IPython extension.\n",
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "ACCOUNT = 'student-03-ec074aee9d21@qwiklabs.net'\n",
    "SAC = 'jupyter-notebook-sac-d'\n",
    "SAC_KEY_DESTINATION = '/media/mujahid7292/Data/Gcloud_Tem_SAC'\n",
    "PROJECT = 'qwiklabs-gcp-03-d8cb7ba1a6f4'\n",
    "BUCKET = 'bucket-qwiklabs-gcp-03-d8cb7ba1a6f4'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ACCOUNT'] = ACCOUNT\n",
    "os.environ['SAC'] = SAC\n",
    "os.environ['SAC_KEY_DESTINATION'] = SAC_KEY_DESTINATION\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Google Application Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='{}/{}.json'.format(SAC_KEY_DESTINATION,SAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Whether Google Application Credential Was Set Successfully Outside Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_APPLICATION_CREDENTIALS=/media/mujahid7292/Data/Gcloud_Tem_SAC/jupyter-notebook-sac-d.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set | grep GOOGLE_APPLICATION_CREDENTIALS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Default Project And Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/account].\n",
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set account $ACCOUNT\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create TensorFlow DNN model </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating a model using the high-level Estimator API \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine CSV, Label and key columns\n",
    "CSV_COLUMNS = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks,key'.split(',')\n",
    "LABEL_COLUMN = 'weight_pounds'\n",
    "KEY_COLUMN = 'key'\n",
    "\n",
    "# Set defaults value for each CSV column\n",
    "DEFAULTS = [[0.0], ['null'], [0.0], ['null'], [0.0], ['nokey']]\n",
    "TRAIN_STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the result to Estimator API\n",
    "def read_dataset(filename, mode, batch_size=512):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        def decode_csv(value_column):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            columns = tf.decode_csv(records=value_column, record_defaults=DEFAULTS)\n",
    "            features = dict(zip(CSV_COLUMNS, columns))\n",
    "            label = features.pop(LABEL_COLUMN)\n",
    "            return features, label\n",
    "        \n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "        \n",
    "        # Create dataset from file list\n",
    "        dataset = (tf.data.TextLineDataset(filenames=file_list) # Read text file\n",
    "                  .map(decode_csv)) # Transform each element by applying decode_csv fn\n",
    "        \n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # Run Indefinietly\n",
    "            dataset = dataset.shuffle(buffer_size = 10*batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # End of input after this\n",
    "        \n",
    "        dataset =dataset.repeat(num_epochs).batch(batch_size)\n",
    "        return dataset\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Define The Features Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature column\n",
    "def get_categorical(name, values):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return tf.feature_column.indicator_column(\n",
    "        categorical_column=tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key=name,\n",
    "            vocabulary_list=values\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_cols():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Define Column Type\n",
    "    return [\\\n",
    "            get_categorical(name='is_male', values=['True', 'False', 'Unknown']),\n",
    "            tf.feature_column.numeric_column('mother_age'),\n",
    "            get_categorical(\n",
    "                name='plurality', \n",
    "                values=['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', 'Quintuplets(5)','Multiple(2+)']\n",
    "            ),\n",
    "            tf.feature_column.numeric_column('gestation_weeks')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the tensorflow model, we also need a serving input function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    \"\"\"\n",
    "    This function will be used to serve prediction after we train the model.\n",
    "    \"\"\"\n",
    "    feature_placeholders={\n",
    "        'is_male':tf.placeholder(dtype=tf.string, shape=[None]),\n",
    "        'mother_age':tf.placeholder(dtype=tf.float32, shape=[None]),\n",
    "        'plurality':tf.placeholder(dtype=tf.string, shape=[None]),\n",
    "        'gestation_weeks':tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "    }\n",
    "    \n",
    "    features = {\n",
    "        key: tf.expand_dims(input=tensor, axis=-1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features,\n",
    "        receiver_tensors=feature_placeholders\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create estimator to train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(ouput_dir):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    EVAL_INTERVAL = 300\n",
    "    \n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        save_checkpoints_secs=EVAL_INTERVAL,\n",
    "        keep_checkpoint_max=3\n",
    "    )\n",
    "    \n",
    "    estimator = tf.estimator.DNNRegressor(\n",
    "        model_dir=ouput_dir,\n",
    "        feature_columns=get_cols(),\n",
    "        hidden_units=[64,32],\n",
    "        config=run_config\n",
    "    )\n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename = 'train.csv',\n",
    "            mode = tf.estimator.ModeKeys.TRAIN,\n",
    "        ),\n",
    "        max_steps=TRAIN_STEPS\n",
    "    )\n",
    "    \n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name='exporter',\n",
    "        serving_input_receiver_fn=serving_input_fn\n",
    "    )\n",
    "    \n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename='eval.csv',\n",
    "            mode=tf.estimator.ModeKeys.EVAL\n",
    "        ),\n",
    "        steps=None,\n",
    "        start_delay_secs=60, # Start evaluating after N seconds\n",
    "        throttle_secs=EVAL_INTERVAL, # Evaluate every N seconds\n",
    "        exporters=exporter\n",
    "    )\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator,\n",
    "        train_spec=train_spec,\n",
    "        eval_spec=eval_spec\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor The Training In Tensorboard\n",
    "Run Below Command in terminal (Note Inside Venv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>$ `tensorboard --logdir babyweight_trained_tf_dnn`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open <a href='http://localhost:6006/'>Tensoarboard</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'babyweight_trained_tf_dnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': None, '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f945a05dfd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 300 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into babyweight_trained_tf_dnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 135605.61, step = 1\n",
      "INFO:tensorflow:global_step/sec: 65.1464\n",
      "INFO:tensorflow:loss = 802.2241, step = 101 (1.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.4437\n",
      "INFO:tensorflow:loss = 597.2787, step = 201 (1.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3948\n",
      "INFO:tensorflow:loss = 688.2983, step = 301 (1.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2602\n",
      "INFO:tensorflow:loss = 560.7596, step = 401 (1.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.42\n",
      "INFO:tensorflow:loss = 585.65784, step = 501 (1.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5244\n",
      "INFO:tensorflow:loss = 629.74304, step = 601 (1.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.532\n",
      "INFO:tensorflow:loss = 581.6304, step = 701 (1.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5173\n",
      "INFO:tensorflow:loss = 643.771, step = 801 (1.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7573\n",
      "INFO:tensorflow:loss = 560.453, step = 901 (1.476 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into babyweight_trained_tf_dnn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 577.7339.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-18-13:26:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained_tf_dnn/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-18-13:26:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.1685369, global_step = 1000, loss = 584.98755\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained_tf_dnn/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"babyweight_trained_tf_dnn/export/exporter/temp-b'1587216368'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "OUTPUTDIR = 'babyweight_trained_tf_dnn'\n",
    "shutil.rmtree(path=OUTPUTDIR, ignore_errors=True) # Start Fresh Each Time\n",
    "tf.summary.FileWriterCache().clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "train_and_evaluate(ouput_dir=OUTPUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
