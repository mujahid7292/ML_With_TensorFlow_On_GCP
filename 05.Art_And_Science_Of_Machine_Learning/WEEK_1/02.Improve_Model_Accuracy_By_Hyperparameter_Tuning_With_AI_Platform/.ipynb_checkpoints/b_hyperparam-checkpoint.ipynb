{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameter tuning with Cloud AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "  * Improve the accuracy of a model by hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'korjjo-ce6d3' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'korjjo-ce6d3_ml_training' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'  # Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Credentialed Accounts\n",
      "ACTIVE  ACCOUNT\n",
      "*       mujahid7292@gmail.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "To set the active account, run:\n",
      "    $ gcloud config set account `ACCOUNT`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud auth list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art and Science of Machine Learning/02.Improve_Model_Accuracy_By_Hyperparameter_Tuning_With_AI_Platform\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project korjjo-ce6d3\n",
    "gcloud config set compute/region us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Create command-line program\n",
    "\n",
    "In order to submit to Cloud AI Platform, we need to create a distributed training program. Let's convert our housing example to fit that paradigm, using the Estimators API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf house_prediction_module\n",
    "mkdir house_prediction_module\n",
    "mkdir house_prediction_module/trainer\n",
    "touch house_prediction_module/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing house_prediction_module/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile house_prediction_module/trainer/task.py\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from . import model\n",
    "    \n",
    "if __name__ == '__main__' and \"get_ipython\" not in dir():\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      type = float, \n",
    "      default = 0.01\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--batch_size',\n",
    "      type = int, \n",
    "      default = 30\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--output_dir',\n",
    "      help = 'GCS location to write checkpoints and export models.',\n",
    "      required = True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--job-dir',\n",
    "      help = 'this model ignores this field, but it is required by gcloud',\n",
    "      default = 'junk'\n",
    "  )\n",
    "  args = parser.parse_args()\n",
    "  arguments = args.__dict__\n",
    "  \n",
    "  # Unused args provided by service\n",
    "  arguments.pop('job_dir', None)\n",
    "  arguments.pop('job-dir', None)\n",
    "  \n",
    "  # Append trial_id to path if we are doing hptuning\n",
    "  # This code can be removed if you are not using hyperparameter tuning\n",
    "  arguments['output_dir'] = os.path.join(\n",
    "      arguments['output_dir'],\n",
    "      json.loads(\n",
    "          os.environ.get('TF_CONFIG', '{}')\n",
    "      ).get('task', {}).get('trial', '')\n",
    "  )\n",
    "  \n",
    "  # Run the training\n",
    "  shutil.rmtree(arguments['output_dir'], ignore_errors=True) # start fresh each time\n",
    "  \n",
    "  # Pass the command line arguments to our model's train_and_evaluate function\n",
    "  model.train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing house_prediction_module/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile house_prediction_module/trainer/model.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Read dataset and split into train and eval\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep = \",\")\n",
    "df['num_rooms'] = df['total_rooms'] / df['households']\n",
    "np.random.seed(seed = 1) #makes split reproducible\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]\n",
    "\n",
    "# Train and eval input functions\n",
    "SCALE = 100000\n",
    "\n",
    "def train_input_fn(df, batch_size):\n",
    "  return tf.estimator.inputs.pandas_input_fn(x = traindf[[\"num_rooms\"]],\n",
    "                                             y = traindf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                             num_epochs = None,\n",
    "                                             batch_size = batch_size, # note the batch size\n",
    "                                             shuffle = True)\n",
    "\n",
    "def eval_input_fn(df, batch_size):\n",
    "  return tf.estimator.inputs.pandas_input_fn(x = evaldf[[\"num_rooms\"]],\n",
    "                                             y = evaldf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                             num_epochs = 1,\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = False)\n",
    "\n",
    "# Define feature columns\n",
    "features = [tf.feature_column.numeric_column('num_rooms')]\n",
    "\n",
    "def train_and_evaluate(args):\n",
    "  # Compute appropriate number of steps\n",
    "  num_steps = (len(traindf) / args['batch_size']) / args['learning_rate']  # if learning_rate=0.01, hundred epochs\n",
    "\n",
    "  # Create custom optimizer\n",
    "  myopt = tf.train.FtrlOptimizer(learning_rate = args['learning_rate']) # note the learning rate\n",
    "\n",
    "  # Create rest of the estimator as usual\n",
    "  estimator = tf.estimator.LinearRegressor(model_dir = args['output_dir'], \n",
    "                                           feature_columns = features, \n",
    "                                           optimizer = myopt)\n",
    "  #Add rmse evaluation metric\n",
    "  def rmse(labels, predictions):\n",
    "    pred_values = tf.cast(predictions['predictions'], tf.float64)\n",
    "    return {'rmse': tf.metrics.root_mean_squared_error(labels * SCALE, pred_values * SCALE)}\n",
    "  estimator = tf.contrib.estimator.add_metrics(estimator, rmse)\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn(df = traindf, batch_size = args['batch_size']),\n",
    "                                      max_steps = num_steps)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn(df = evaldf, batch_size = len(evaldf)),\n",
    "                                    steps = None)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ai-platform.local.train) unrecognized arguments:\n",
      "  and\n",
      "  Science\n",
      "  of\n",
      "  Machine\n",
      "  Learning/02.Improve_Model_Accuracy_By_Hyperparameter_Tuning_With_AI_Platform/trainer\n",
      "  To search the help text of gcloud commands, run:\n",
      "  gcloud help -- SEARCH_TERMS\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'rm -rf house_trained\\nexport PYTHONPATH=${PYTHONPATH}:${pwd}/house_prediction_module\\ngcloud ai-platform local train \\\\\\n    --module-name=trainer.task \\\\\\n    --job-dir=house_trained \\\\\\n    --package-path=$(pwd)/trainer \\\\\\n    -- \\\\\\n    --batch_size=30 \\\\\\n    --learning_rate=0.02 \\\\\\n    --output_dir=house_trained\\n'' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-45f3215c8cc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bash'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rm -rf house_trained\\nexport PYTHONPATH=${PYTHONPATH}:${pwd}/house_prediction_module\\ngcloud ai-platform local train \\\\\\n    --module-name=trainer.task \\\\\\n    --job-dir=house_trained \\\\\\n    --package-path=$(pwd)/trainer \\\\\\n    -- \\\\\\n    --batch_size=30 \\\\\\n    --learning_rate=0.02 \\\\\\n    --output_dir=house_trained\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\InstalledSoftware\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2321\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2322\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2323\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2324\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\InstalledSoftware\\Anaconda\\lib\\site-packages\\IPython\\core\\magics\\script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[1;34m(line, cell)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;31m# write a basic docstring:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32mD:\\InstalledSoftware\\Anaconda\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\InstalledSoftware\\Anaconda\\lib\\site-packages\\IPython\\core\\magics\\script.py\u001b[0m in \u001b[0;36mshebang\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'b'rm -rf house_trained\\nexport PYTHONPATH=${PYTHONPATH}:${pwd}/house_prediction_module\\ngcloud ai-platform local train \\\\\\n    --module-name=trainer.task \\\\\\n    --job-dir=house_trained \\\\\\n    --package-path=$(pwd)/trainer \\\\\\n    -- \\\\\\n    --batch_size=30 \\\\\\n    --learning_rate=0.02 \\\\\\n    --output_dir=house_trained\\n'' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf house_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${pwd}/house_prediction_module\n",
    "gcloud ai-platform local train \\\n",
    "    --module-name=trainer.task \\\n",
    "    --job-dir=house_trained \\\n",
    "    --package-path=$(pwd)/trainer \\\n",
    "    -- \\\n",
    "    --batch_size=30 \\\n",
    "    --learning_rate=0.02 \\\n",
    "    --output_dir=house_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create hyperparam.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 5\n",
    "    maxParallelTrials: 1\n",
    "    hyperparameterMetricTag: rmse\n",
    "    params:\n",
    "    - parameterName: batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 64\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.01\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LOG_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/house_trained   # CHANGE bucket name appropriately\n",
    "gsutil rm -rf $OUTDIR\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/house_prediction_module\n",
    "gcloud ai-platform jobs submit training house_$(date -u +%y%m%d_%H%M%S) \\\n",
    "   --config=hyperparam.yaml \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=$(pwd)/house_prediction_module/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   --\\\n",
    "   --output_dir=$OUTDIR \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gcloud ai-platform jobs describe house_180912_195904 # CHANGE jobId appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge exercise\n",
    "Add a few engineered features to the housing model, and use hyperparameter tuning to choose which set of features the model uses.\n",
    "\n",
    "<p>\n",
    "Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
