{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable Virtual Environment For This Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate Conda Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ conda activate`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Or Upgrade necessary software for virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ sudo apt-get install --upgrade python3-pip`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ sudo pip3 install --upgrade virtualenv`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ sudo pip3 install --upgrade setuptools`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will go to the location of the directory, where we will create our virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ cd /media/mujahid7292/Data/GoogleDri\n",
    "rning/WEEK_3/01.Using_Custom_Estimatorsmujahid7292@mujahid7292-HP-ENVY-Notebook:/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimat`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deactivate conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ conda deactivate`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Virtual Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ virtualenv Venv`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate newly created virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ source Venv/bin/activate`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ (Venv) which python`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ (Venv) pip list`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`$ (Venv) pip3 install jupyter`</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "numpy\n",
    "pandas\n",
    "seaborn\n",
    "tensorflow==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/05_artandscience/d_customestimator.ipynb</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Time series prediction using RNNs, with TensorFlow and Cloud ML Engine </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating a Recurrent Neural Network in TensorFlow\n",
    "<li> Creating a Custom Estimator in tf.estimator\n",
    "<li> Training on Cloud ML Engine\n",
    "</ol>\n",
    "\n",
    "<p>\n",
    "\n",
    "<h3> Simulate some time-series data </h3>\n",
    "\n",
    "Essentially a set of sinusoids with random amplitudes and frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'ml-practice-260405'\n",
    "BUCKET = 'bucket-ml-practice-260405'\n",
    "REGION = 'us-central1'\n",
    "os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random time series generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "SEQ_LEN = 10\n",
    "def create_timeseries():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    freq = (np.random.random() *0.5) + 0.1 # 0.1 to 0.6\n",
    "    ampl = np.random.random() + 0.5 # 0.5 to 1.5\n",
    "    x = np.sin(np.arange(0, SEQ_LEN) * freq) * ampl\n",
    "    return x\n",
    "\n",
    "# Plot our time series data\n",
    "for i in range(0,5):\n",
    "    sns.lineplot(data=create_timeseries()) # 5 Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(filename, N):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with open(file=filename, mode='w') as ofp:\n",
    "        for lineno in range(0, N):\n",
    "            seq = create_timeseries()\n",
    "            line = \",\".join(map(str, seq))\n",
    "            ofp.write(line + '\\n')\n",
    "            \n",
    "to_csv('train.csv', 1000) # 1000 Sequences\n",
    "to_csv('valid.csv', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> train.csv <==\r\n",
      "0.0,0.2846975031846363,0.5577225722601126,0.8078813362114603,1.0249174294001042,1.199932496664106,1.325751020768865,1.3972145144923407,1.411393015638284,1.3677052138034018\r\n",
      "0.0,0.08050965668107063,0.15918547506966776,0.23423538779896313,0.30394991790080883,0.3667411170456152,0.42117873561900077,0.4660228007580032,0.5002518602886573,0.5230862492282725\r\n",
      "0.0,0.4833623659951605,0.8481459271028067,1.0048617165315328,0.9150641035810628,0.6007823035451765,0.13911615469826166,-0.356678069739941,-0.7649717723858219,-0.9856020470868334\r\n",
      "0.0,0.41318310276072184,0.7067185736708541,0.795605782927576,0.6541051878963634,0.32319186957112234,-0.1013098398794529,-0.4964747193780086,-0.7478727699564935,-0.782705319058858\r\n",
      "0.0,0.5869255807640114,1.0503853041986508,1.2928856311451626,1.2634141134322987,0.9681703891751328,0.46926202487140883,-0.12836045262098728,-0.6989809832747286,-1.1225636454399242\r\n",
      "\r\n",
      "==> valid.csv <==\r\n",
      "0.0,0.44927125153099895,0.8283523059075627,1.0780188663300856,1.1592652206832053,1.0593981516495634,0.7940200135770504,0.4045911575749596,-0.04804746985219683,-0.493179582294909\r\n",
      "0.0,0.39446111533717737,0.682733552856445,0.7872145583158517,0.6797779124368845,0.38934549099258814,-0.005898485495677003,-0.3995545934930802,-0.6856508626383425,-0.7871703618121473\r\n",
      "0.0,0.0858147614328549,0.169340718988533,0.2483501145015826,0.3207356530525257,0.3845667075730047,0.4381408114636681,0.480029065842158,0.509114250344182,0.5246206210074534\r\n",
      "0.0,0.15378970116399165,0.3002616932676989,0.43244646264679487,0.5440543183974293,0.6297746720273699,0.6855287288991284,0.7086635677570546,0.6980783735359164,0.6542768169696486\r\n",
      "0.0,0.4135173344173898,0.7101767616329702,0.8061438279715571,0.6742987258719397,0.351900214336029,-0.0699435179162374,-0.47202156576850324,-0.7407087065441806,-0.8000753132366509\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 train.csv valid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> RNN </h2>\n",
    "\n",
    "For more info, see:\n",
    "<ol>\n",
    "<li> http://colah.github.io/posts/2015-08-Understanding-LSTMs/ for the theory\n",
    "<li> https://www.tensorflow.org/tutorials/recurrent for explanations\n",
    "<li> https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb for sample code\n",
    "</ol>\n",
    "\n",
    "Here, we are trying to predict from 9 values of a timeseries, the tenth value.\n",
    "\n",
    "<p>\n",
    "\n",
    "<h3> Imports </h3>\n",
    "\n",
    "Several tensorflow packages and shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "import tensorflow.contrib.rnn as rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Input Fn to read CSV </h3>\n",
    "\n",
    "Our CSV file structure is quite simple -- a bunch of floating point numbers (note the type of DEFAULTS). We ask for the data to be read BATCH_SIZE sequences at a time.  The Estimator API in tf.contrib.learn wants the features returned as a dict. We'll just call this timeseries column 'rawdata'.\n",
    "<p>\n",
    "Our CSV file sequences consist of 10 numbers. We'll assume that 9 of them are inputs and we need to predict the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULTS = [[0.0] for x in range(0, SEQ_LEN)]\n",
    "BATCH_SIZE = 20\n",
    "TIMESERIES_COL = 'rawdata'\n",
    "# In each sequence, column index 0 to N_INPUTS - 1 are features, and column \n",
    "# index N_INPUTS to SEQ_LEN are labels\n",
    "N_OUTPUTS = 1\n",
    "N_INPUTS = SEQ_LEN - N_OUTPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data using the Estimator API in tf.estimator requires an input_fn. This input_fn needs to return a dict of features and the corresponding labels.\n",
    "<p>\n",
    "So, we read the CSV file.  The Tensor format here will be a scalar -- entire line.  We then decode the CSV. At this point, all_data will contain a list of scalar Tensors. There will be SEQ_LEN of these tensors.\n",
    "<p>\n",
    "We split this list of SEQ_LEN tensors into a list of N_INPUTS Tensors and a list of N_OUTPUTS Tensors. We stack them along the first dimension to then get a vector Tensor for each.  We then put the inputs into a dict and call it features.  The other is the ground truth, so labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and convert to needed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename, mode, batch_size=512):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"\n",
    "        Provide the ability to decode a CSV\n",
    "        \"\"\"\n",
    "        def decode_csv(line):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # all_data is a list of scalar tensor\n",
    "            all_data = tf.decode_csv(records=line, record_defaults=DEFAULTS)\n",
    "            inputs = all_data[:len(all_data) - N_OUTPUTS] # First N Inputs Value\n",
    "            labels = all_data[len(all_data) - N_OUTPUTS:] # Last N Outputs Value\n",
    "            \n",
    "            # Convert each list of rank R tensors to one rank R+1 tensors\n",
    "            inputs = tf.stack(values=inputs, axis=0)\n",
    "            labels = tf.stack(values=labels, axis=0)\n",
    "            \n",
    "            # Convert input R+1 tensor into a feature dictionary of one R+1 tensor\n",
    "            features = {TIMESERIES_COL: inputs}\n",
    "            \n",
    "            return features, labels\n",
    "        \n",
    "        # Create list of file that match pattern\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "        \n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(filenames=file_list).map(decode_csv)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # Run Indefinietly\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # End of input after this\n",
    "        \n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        \n",
    "        batch_features, batch_labels = iterator.get_next()\n",
    "        \n",
    "        return batch_features, batch_labels\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define RNN </h3>\n",
    "\n",
    "A recursive neural network consists of possibly stacked LSTM cells.\n",
    "<p>\n",
    "The RNN has one output per input, so it will have 8 output cells.  We use only the last output cell, but rather use it directly, we do a matrix multiplication of that cell by a set of weights to get the actual predictions. This allows for a degree of scaling between inputs and predictions if necessary (we don't really need it in this problem).\n",
    "<p>\n",
    "Finally, to supply a model function to the Estimator API, you need to return a EstimatorSpec. The rest of the function creates the necessary objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SIZE = 3 # Number of hidden layer in each of the LSTM cells\n",
    "\n",
    "# Create the inference model\n",
    "def simple_rnn(features, labels, mode):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # 0. Reformat input shape to become a sequence\n",
    "    x = tf.split(\n",
    "        value=features[TIMESERIES_COL],\n",
    "        num_or_size_splits=N_INPUTS,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 1. Configure the rnn\n",
    "    lstm_cell = rnn.BasicLSTMCell(\n",
    "        num_units=LSTM_SIZE,\n",
    "        forget_bias=1.0\n",
    "    )\n",
    "    outputs, _ = rnn.static_rnn(\n",
    "        cell=lstm_cell,\n",
    "        inputs=x,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    \n",
    "    # Slice to keep only the last cell of the RNN\n",
    "    outputs = outputs[-1]\n",
    "    \n",
    "    # Output is result of linear activation of last layer of RNN\n",
    "    weight = tf.get_variable(\n",
    "        name='weight',\n",
    "        initializer=tf.initializers.random_normal,\n",
    "        shape=[LSTM_SIZE, N_OUTPUTS]\n",
    "    )\n",
    "    bias = tf.get_variable(\n",
    "        name='bias',\n",
    "        initializer=tf.initializers.random_normal,\n",
    "        shape=[N_OUTPUTS]\n",
    "    )\n",
    "\n",
    "    predictions = tf.matmul(outputs, weight) + bias\n",
    "    \n",
    "    # 2. Loss function, training/eval ops\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        # Our loss function\n",
    "        loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "        # Our training optimizer\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=0.01,\n",
    "            optimizer='SGD'\n",
    "        )\n",
    "        # Our evaluation metric optimizer\n",
    "        eval_metric_ops = {\n",
    "            'rmse':tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "        }\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    "    \n",
    "    # 3. Create predictions\n",
    "    predictions_dict = {'predicted':predictions}\n",
    "    \n",
    "    # 4. Create export output\n",
    "    export_outputs = {\n",
    "        \"predicted_export_outputs\": tf.estimator.export.PredictOutput(outputs=predictions)\n",
    "    }\n",
    "    \n",
    "    # 5. Return estimator spec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = export_outputs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Estimator </h3>\n",
    "\n",
    "Distributed training is launched off using an Estimator.  The key line here is that we use tf.estimator.Estimator rather than, say tf.estimator.DNNRegressor.  This allows us to provide a model_fn, which will be our RNN defined above.  Note also that we specify a serving_input_fn -- this is how we parse the input data provided to us at prediction time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to read in respected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return read_dataset(\n",
    "        filename='train.csv',\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        batch_size=512\n",
    "    )\n",
    "\n",
    "def get_valid():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return read_dataset(\n",
    "        filename='valid.csv',\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        batch_size=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create serving input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    feature_placeholders = {\n",
    "        TIMESERIES_COL: tf.placeholder(dtype=tf.float32, shape=[None, N_INPUTS])\n",
    "    }\n",
    "    \n",
    "    features = {\n",
    "        key: tf.expand_dims(input=tensor, axis=-1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    \n",
    "    features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis = [2])\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom estimator's train and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=simple_rnn,\n",
    "        model_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=get_train(),\n",
    "        max_steps=1000\n",
    "    )\n",
    "    \n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        'exporter', \n",
    "        serving_input_fn\n",
    "    )\n",
    "    \n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=get_valid(),\n",
    "        steps=None,\n",
    "        exporters=exporter\n",
    "    )\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'outputdir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3043ac4160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.47178686, step = 1\n",
      "INFO:tensorflow:global_step/sec: 33.5116\n",
      "INFO:tensorflow:loss = 0.19885325, step = 101 (2.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7316\n",
      "INFO:tensorflow:loss = 0.14166778, step = 201 (3.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7078\n",
      "INFO:tensorflow:loss = 0.10256486, step = 301 (3.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7591\n",
      "INFO:tensorflow:loss = 0.071880445, step = 401 (2.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1412\n",
      "INFO:tensorflow:loss = 0.050940257, step = 501 (2.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7575\n",
      "INFO:tensorflow:loss = 0.040836662, step = 601 (2.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1317\n",
      "INFO:tensorflow:loss = 0.033115026, step = 701 (2.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0473\n",
      "INFO:tensorflow:loss = 0.024454959, step = 801 (2.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1324\n",
      "INFO:tensorflow:loss = 0.019683708, step = 901 (2.930 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015037837.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-02-05:13:44\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-02-05:13:45\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.013999057, rmse = 0.11831761\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predicted_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"outputdir/export/exporter/temp-b'1585804425'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree('outputdir', ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate('outputdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Standalone Python module </h3>\n",
    "\n",
    "To train this on Cloud ML Engine, we take the code in this notebook and make a standalone Python module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create command line programme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to submit to `Cloud AI Platform`, we need to create a distributed training programme. Let's convert our time series example to fit that paradigm, using the Estimator API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf simple_rnn\n",
    "mkdir simple_rnn\n",
    "mkdir simple_rnn/trainer\n",
    "touch simple_rnn/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing simple_rnn/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_rnn/trainer/task.py\n",
    "\n",
    "\"\"\"\n",
    "Example implementation of code to run on the Cloud ML service\n",
    "\"\"\"\n",
    "\n",
    "import traceback\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from .import model\n",
    "\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Create object of ArgumentParser class\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Input arguments\n",
    "    parser.add_argument(\n",
    "        '--train_data_paths',\n",
    "        help = 'GCS or local path to training data',\n",
    "        required=True\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--eval_data_paths',\n",
    "        help = 'GCS or local path to evaluation data',\n",
    "        required=True\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--output_dir',\n",
    "        help = 'GCS location to write checkpoints and export models',\n",
    "        required=True\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help = 'This model ignore this field, but it is required by gcloud',\n",
    "        default='junk'\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--keras',\n",
    "        help = 'Use the keras variant',\n",
    "        action = 'store_true'\n",
    "    )\n",
    "    \n",
    "    # Eval arguments\n",
    "    parser.add_argument(\n",
    "        '--eval_delay_secs',\n",
    "        help = 'How long to wait before running first evaluation',\n",
    "        default = 10,\n",
    "        type = int\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--min_eval_frequency',\n",
    "        help = 'Minimum number of training steps between evaluations',\n",
    "        default = 1,\n",
    "        type = int\n",
    "    )\n",
    "    \n",
    "    # Now parse those above arguments\n",
    "    args = parser.parse_args()\n",
    "    arguments = args.__dict__\n",
    "    \n",
    "    # Unused args provided by service\n",
    "    arguments.pop('job_dir', None)\n",
    "    arguments.pop('job-dir', None)\n",
    "    \n",
    "    output_dir = arguments.pop('output_dir')\n",
    "\n",
    "    # Append trial_id to path if we are doing hptuning\n",
    "    # This code can be removed if you are not using hyperparameter tuning\n",
    "    output_dir = os.path.join(\n",
    "        output_dir,\n",
    "        json.loads(\n",
    "            os.environ.get('TF_CONFIG', '{}')\n",
    "        ).get('task', {}).get('trial', '')\n",
    "    )\n",
    "\n",
    "    # Run the training job\n",
    "    try:\n",
    "        shutil.rmtree(output_dir, ignore_errors = True) # start fresh each time\n",
    "        model.train_and_evaluate(output_dir, arguments['keras'])\n",
    "    except:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simple_rnn/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_rnn/trainer/model.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "SEQ_LEN = 10\n",
    "DEFAULTS = [[0.0] for x in range(0,SEQ_LEN)]\n",
    "BATCH_SIZE = 20\n",
    "TIMESERIES_INPUT_LAYER = 'rawdata'\n",
    "TIMESERIES_COL = '{}.input'.format(TIMESERIES_INPUT_LAYER)\n",
    "# In each sequence, column index 0 to (N_INPUTS - 1) are features, and \n",
    "# column index N_INPUTS to SEQ_LEN are labels. Example: here first 9 inputs\n",
    "# are features and 10th inputs are label\n",
    "N_OUTPUTS = 1\n",
    "N_INPUTS = SEQ_LEN - N_OUTPUTS # e.g: 10 - 1 = 9\n",
    "LSTM_SIZE = 3 # NUmber of hidden layer in each of the lstm cell\n",
    "\n",
    "# Read data and convert to needed format\n",
    "def read_dataset(filename, mode, batch_size):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"\n",
    "        Provide the ability to decode a csv\n",
    "        \"\"\"\n",
    "        def decode_csv(line):\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # all_data is a list of scalar tensor\n",
    "            all_data = tf.decode_csv(\n",
    "                records=line,\n",
    "                record_defaults=DEFAULTS\n",
    "            )\n",
    "            inputs = all_data[:len(all_data) - N_OUTPUTS]  # first N_INPUTS values\n",
    "            labels = all_data[len(all_data) - N_OUTPUTS:] # last N_OUTPUTS values\n",
    "\n",
    "            # Convert each list of rank R tensors to one rank R+1 tensor\n",
    "            inputs = tf.stack(inputs, axis = 0)\n",
    "            labels = tf.stack(labels, axis = 0)\n",
    "            \n",
    "            # Convert input R+1 tensor into a feature dictionary of one R+1 tensor\n",
    "            features = {TIMESERIES_COL: inputs}\n",
    "            \n",
    "            return features, labels\n",
    "        \n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        batch_features, batch_labels = iterator.get_next()\n",
    "        \n",
    "        return batch_features, batch_labels\n",
    "    return _input_fn\n",
    "\n",
    "# Create inference model usin keras.\n",
    "# The model here is a dnn regressor.\n",
    "def make_keras_estimator(output_dir):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(\n",
    "        32, \n",
    "        input_shape=(N_INPUTS,), \n",
    "        name=TIMESERIES_INPUT_LAYER\n",
    "    ))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer='adam',\n",
    "        metrics=['mae','mape'] # mean absolute [percentage] error\n",
    "    )\n",
    "    \n",
    "    return keras.estimator.model_to_estimator(model, model_dir=output_dir)\n",
    "\n",
    "# Create the inference model\n",
    "def simple_rnn(features, labels, mode):\n",
    "    # 0. Reformat input shape to become a sequence\n",
    "    x = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)\n",
    "\n",
    "    # 1. Configure the RNN\n",
    "    lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias = 1.0)\n",
    "    outputs, _ = rnn.static_rnn(lstm_cell, x, dtype = tf.float32)\n",
    "\n",
    "    # Slice to keep only the last cell of the RNN\n",
    "    outputs = outputs[-1]\n",
    "    #print('last outputs={}'.format(outputs))\n",
    "\n",
    "    # Output is result of linear activation of last layer of RNN\n",
    "    weight = tf.get_variable(\"weight\", initializer=tf.initializers.random_normal, \n",
    "\t\t\t     shape=[LSTM_SIZE, N_OUTPUTS])\n",
    "    bias = tf.get_variable(\"bias\", initializer=tf.initializers.random_normal, \n",
    "\t\t\t   shape=[N_OUTPUTS])\n",
    "    predictions = tf.matmul(outputs, weight) + bias\n",
    "    \n",
    "    # 2. Loss function, training/eval ops\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss = loss,\n",
    "            global_step = tf.train.get_global_step(),\n",
    "            learning_rate = 0.01,\n",
    "            optimizer = \"SGD\")\n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "        }\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    "  \n",
    "    # 3. Create predictions\n",
    "    predictions_dict = {\"predicted\": predictions}\n",
    "    \n",
    "    # 4. Create export outputs\n",
    "    export_outputs = {\"predict_export_outputs\": tf.estimator.export.PredictOutput(outputs = predictions)}\n",
    "\n",
    "    # 4. Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = predictions_dict,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = export_outputs)\n",
    "\n",
    "# Create serving input function\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
    "    }\n",
    "\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis = [2])\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "\n",
    "# Create custom estimator's train and evaluate function\n",
    "def train_and_evaluate(output_dir, use_keras):\n",
    "    if use_keras:\n",
    "       estimator = make_keras_estimator(output_dir)\n",
    "    else:\n",
    "       estimator = tf.estimator.Estimator(model_fn = simple_rnn, \n",
    "                                          model_dir = output_dir)\n",
    "    train_spec = tf.estimator.TrainSpec(read_dataset('train.csv',\n",
    "                                            tf.estimator.ModeKeys.TRAIN,\n",
    "                                            512),\n",
    "                                        max_steps = 1000)\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(read_dataset('valid.csv',\n",
    "                                            tf.estimator.ModeKeys.EVAL,\n",
    "                                            512),\n",
    "                                      steps = None, \n",
    "                                      exporters = exporter)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Practice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'outputdir/eval': Directory not empty\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'outputdir/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2a95cde3c8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2020-04-02 16:50:46.750190: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.5710182, step = 1\n",
      "INFO:tensorflow:global_step/sec: 34.9499\n",
      "INFO:tensorflow:loss = 0.54330266, step = 101 (2.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8777\n",
      "INFO:tensorflow:loss = 0.3191537, step = 201 (2.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9183\n",
      "INFO:tensorflow:loss = 0.198119, step = 301 (3.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3452\n",
      "INFO:tensorflow:loss = 0.1298959, step = 401 (2.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5511\n",
      "INFO:tensorflow:loss = 0.11068614, step = 501 (2.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5597\n",
      "INFO:tensorflow:loss = 0.09810313, step = 601 (2.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2639\n",
      "INFO:tensorflow:loss = 0.08241, step = 701 (2.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.6286\n",
      "INFO:tensorflow:loss = 0.07287793, step = 801 (2.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5111\n",
      "INFO:tensorflow:loss = 0.06884446, step = 901 (2.739 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.06424873.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-02-10:51:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-02-10:51:16\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.053487048, rmse = 0.23127267\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"outputdir/export/exporter/temp-b'1585824676'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Run model as it is\n",
    "# First remove the outputdir\n",
    "rm -rf outputdir\n",
    "echo $PWD\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/simple_rnn\n",
    "python -m trainer.task \\\n",
    "    --train_data_paths=\"${PWD}/train.csv*\" \\\n",
    "    --eval_data_path=\"${PWD}/valid.csv*\" \\\n",
    "    --output_dir=outputdir \\\n",
    "    --job-dir=./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out online prediction.  This is how the REST API will work after you train on Cloud ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.json\n",
    "{\"rawdata_input\": [0,0.214,0.406,0.558,0.655,0.687,0.65,0.549,0.393]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "If the signature defined in the model is not serving_default then you must specify it via --signature-name flag, otherwise the command may fail.\n",
      "ERROR: (gcloud.ml-engine.local.predict) RuntimeError: Bad magic number in .pyc file\n",
      "\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b\"# local predict doesn't work with Python 3 yet.\\nMODEL_DIR=$(ls ./outputdir/export/exporter/)\\ngcloud ml-engine local predict --model-dir=./outputdir/export/exporter/$MODEL_DIR --json-instances=test.json\\n\"' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7745d80bee5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# local predict doesn't work with Python 3 yet.\\nMODEL_DIR=$(ls ./outputdir/export/exporter/)\\ngcloud ml-engine local predict --model-dir=./outputdir/export/exporter/$MODEL_DIR --json-instances=test.json\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b\"# local predict doesn't work with Python 3 yet.\\nMODEL_DIR=$(ls ./outputdir/export/exporter/)\\ngcloud ml-engine local predict --model-dir=./outputdir/export/exporter/$MODEL_DIR --json-instances=test.json\\n\"' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# local predict doesn't work with Python 3 yet.\n",
    "MODEL_DIR=$(ls ./outputdir/export/exporter/)\n",
    "gcloud ml-engine local predict --model-dir=./outputdir/export/exporter/$MODEL_DIR --json-instances=test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cloud ML Engine </h3>\n",
    "\n",
    "Now to train on Cloud ML Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run module on Cloud ML Engine\n",
    "OUTDIR=gs://${BUCKET}/simplernn/model_trained\n",
    "JOBNAME=simplernn_$(date -u +%y%m%d_%H%M%S)\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/simplernn/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --runtime-version=1.4 \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/train.csv*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/valid.csv*\"  \\\n",
    "   --output_dir=$OUTDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Variant: long sequence </h2>\n",
    "\n",
    "To create short sequences from a very long sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input= [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "output= [[1. 2. 3. 4. 5.]\n",
      " [2. 3. 4. 5. 6.]\n",
      " [3. 4. 5. 6. 7.]\n",
      " [4. 5. 6. 7. 8.]\n",
      " [5. 6. 7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def breakup(sess, x, lookback_len):\n",
    "  N = sess.run(tf.size(x))\n",
    "  windows = [tf.slice(x, [b], [lookback_len]) for b in range(0, N-lookback_len)]\n",
    "  windows = tf.stack(windows)\n",
    "  return windows\n",
    "\n",
    "x = tf.constant(np.arange(1,11, dtype=np.float32))\n",
    "with tf.Session() as sess:\n",
    "    print('input=', x.eval())\n",
    "    seqx = breakup(sess, x, 5)\n",
    "    print('output=', seqx.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant: Keras\n",
    "\n",
    "You can also invoke a Keras model from within the Estimator framework by creating an estimator from the compiled Keras model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keras_estimator(output_dir):\n",
    "  from tensorflow import keras\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(keras.layers.Dense(32, input_shape=(N_INPUTS,), name=TIMESERIES_INPUT_LAYER))\n",
    "  model.add(keras.layers.Activation('relu'))\n",
    "  model.add(keras.layers.Dense(1))\n",
    "  model.compile(loss = 'mean_squared_error',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['mae', 'mape']) # mean absolute [percentage] error\n",
    "  return keras.estimator.model_to_estimator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Practice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'outputdir/eval': Directory not empty\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Practice/outputdir/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8a81c74278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "2020-04-02 16:56:20.139293: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Practice/simple_rnn/trainer/task.py\", line 89, in <module>\n",
      "    model.train_and_evaluate(output_dir, arguments['keras'])\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Practice/simple_rnn/trainer/model.py\", line 173, in train_and_evaluate\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 439, in train_and_evaluate\n",
      "    executor.run()\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 518, in run\n",
      "    self.run_local()\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 650, in run_local\n",
      "    hooks=train_hooks)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 843, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 856, in _train_model_default\n",
      "    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 831, in _call_model_fn\n",
      "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py\", line 330, in model_fn\n",
      "    labels)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py\", line 267, in _clone_and_build_model\n",
      "    is_input=True)\n",
      "  File \"/media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/05.Art_And_Science_Of_Machine_Learning/WEEK_3/01.Using_Custom_Estimators/Venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py\", line 110, in _create_ordered_io\n",
      "    ', '.join(keras_io_names)))\n",
      "ValueError: Cannot find input with name \"rawdata.input\" in Keras Model. It needs to match one of the following: rawdata_input\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Run module as-is\n",
    "echo $PWD\n",
    "rm -rf outputdir\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/simple_rnn\n",
    "python -m trainer.task \\\n",
    "  --train_data_paths=\"${PWD}/train.csv*\" \\\n",
    "  --eval_data_paths=\"${PWD}/valid.csv*\"  \\\n",
    "  --output_dir=${PWD}/outputdir \\\n",
    "  --job-dir=./tmp --keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
