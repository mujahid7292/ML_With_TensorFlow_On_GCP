{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with TensorFlow\n",
    "This notebook demonstrates how to implement a simple linear image models on MNIST using Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data\n",
    "Let's download MNIST data and examine the shape. We will need these numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "NCLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 69s 6us/step\n",
      "x_train.shape = (60000, 28, 28)\n",
      "y_train.shape = (60000, 10)\n",
      "x_test.shape = (10000, 28, 28)\n",
      "y_test.shape = (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Get mnist data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Scale our feature (image) between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test /255.0\n",
    "\n",
    "# Convert lables to categorical one hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y = y_train, num_classes=NCLASSES)\n",
    "y_test  = tf.keras.utils.to_categorical(y = y_test, num_classes=NCLASSES)\n",
    "\n",
    "print(\"x_train.shape = {}\".format(x_train.shape))\n",
    "print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "print(\"x_test.shape = {}\".format(x_test.shape))\n",
    "print(\"y_test.shape = {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f84b87a0550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN30lEQVR4nO3df6zV9X3H8ddLvKCAOsCBTFlxrbOl27zqLa5hXWnZGkvSostcJGlHNzearJq62K5Gs+IfS2q2tbXrnBlWVtr4I26KsMVsEkZim7bMK1J+CM5fUNEbsGUrtFUE7nt/3K/LLd7zOZfzG97PR3Jzzvm+z/d83/mGF9/vOZ/vOR9HhACc+k7rdgMAOoOwA0kQdiAJwg4kQdiBJE7v5MYmelKcoSmd3CSQyuv6qd6Iwx6r1lTYbV8p6SuSJkj6WkTcXnr+GZqiK7yomU0CKNgUG2rWGj6Ntz1B0p2SPixpnqSltuc1+noA2quZ9+zzJT0XES9ExBuSHpC0pDVtAWi1ZsJ+vqSXRj3eWy37ObaX2x60PXhEh5vYHIBmNBP2sT4EeMu1txGxMiIGImKgT5Oa2ByAZjQT9r2S5ox6fIGkV5prB0C7NBP2JyRdZPtC2xMlXStpXWvaAtBqDQ+9RcRR29dL+g+NDL2tiogdLesMQEs1Nc4eEY9KerRFvQBoIy6XBZIg7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTR1JTNtndLOiTpmKSjETHQiqYAtF5TYa98ICJ+2ILXAdBGnMYDSTQb9pD0mO0nbS8f6wm2l9setD14RIeb3ByARjV7Gr8gIl6xPVPSetu7IuLx0U+IiJWSVkrS2Z4eTW4PQIOaOrJHxCvV7X5JayTNb0VTAFqv4bDbnmL7rDfvS/qQpO2tagxAazVzGj9L0hrbb77OfRHx7y3pCkDLNRz2iHhB0iUt7AVAGzH0BiRB2IEkCDuQBGEHkiDsQBKt+CIMetixhZcV66d/fl+x/q8XryvW+zyhWD8Sx2rWFmy5trjujFv7inXvfrlY/9FH5tWsTX+kfEnI8KFDxfrJiCM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPtJwJMmFeuHPtpfs7biC6uK677/zJ8V68PFqnSkzm8PDRde4Vv99xXXvewvP1GsX3Je+Vi1du7f16y95xduKK4766vfKdZPRhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlPAocX/nqx/p931B5Prmfja1OL9c//1R8X630/a3ySn4NvKx9rJpYvAdBffKZ8DcGPh4/WrE0dqv09+1MVR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9h4Q7y1PhvuFu/6x4dde+vziYv3gijnF+rSN32142/Wc844Li/X+f36+WH/XxPKx6p1r/7xm7Vf/ZVNx3VNR3SO77VW299vePmrZdNvrbT9b3U5rb5sAmjWe0/ivS7ryuGU3S9oQERdJ2lA9BtDD6oY9Ih6XdOC4xUskra7ur5Z0VYv7AtBijX5ANysihiSpup1Z64m2l9setD14RIcb3ByAZrX90/iIWBkRAxEx0KfyDycCaJ9Gw77P9mxJqm73t64lAO3QaNjXSVpW3V8maW1r2gHQLnXH2W3fL2mhpHNt75W0QtLtkh60fZ2kH0i6pp1Nnur+59bXivXL67z7Wbzr92rWJnzm7OK6E57aXH7xNvrfy2cV6ytmPtjU6895rKnVTzl1wx4RS2uUFrW4FwBtxOWyQBKEHUiCsANJEHYgCcIOJMFXXDvgxQd+o1jfcek/Fet7j5aH5k67tfaXDuOprcV126003fQ7bny6uO5pdY5Ff7SnPCB05iP/Vaxnw5EdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0D/nBeebx3WMPF+p6j5a+p6nvdG0svjaNL0jN31P6Z7LW/fGdx3fJekfb8zcXF+mTl+7noEo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+womvDu8lj2zhvOKdZ3faQ8ll6y8bWpxfpZ33mxWD/W8JZPTRzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtk74KEX+4v1z87YVqxfOumnxfr7tr5+wj2N1/zJDxfrHzizvO1630kvuen7v1+sX7BvRxOvnk/dI7vtVbb3294+atlttl+2vaX6W9zeNgE0azyn8V+XdOUYy78cEf3V36OtbQtAq9UNe0Q8LulAB3oB0EbNfEB3ve2t1Wl+zcnGbC+3PWh78IgON7E5AM1oNOx3SXq7pH5JQ5K+WOuJEbEyIgYiYqBP5R8nBNA+DYU9IvZFxLGIGJZ0t6T5rW0LQKs1FHbbs0c9vFrS9lrPBdAb6o6z275f0kJJ59reK2mFpIW2+yWFpN2SPtnGHk96533s5WL9o49cXaz/2zvXFuv1xunb6X2fu6FYH176o5q1b/XfV1x35t2TG+oJY6sb9ohYOsbie9rQC4A24nJZIAnCDiRB2IEkCDuQBGEHkuArrh0wfOhQ+QmLyvUPXv1nxfr+yxv/P3vazijWz7n3e8X6q98sXwK9q/+BmrV7fjy3uO7kHUPF+tFiFcfjyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOfhKYvGZTsT53TYcaGcOuD36tWB8u/Jj0nc+8v7juL730dEM9YWwc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZUTTh3RfXecaTxeqeo2/UrM36uzMa6AiN4sgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo6iF1ZMbGr9a576k5q18zZubuq1cWLqHtltz7G90fZO2ztsf7paPt32etvPVrfT2t8ugEaN5zT+qKSbIuJdkn5T0qdsz5N0s6QNEXGRpA3VYwA9qm7YI2IoIjZX9w9J2inpfElLJK2unrZa0lXtahJA807oAzrbcyVdKmmTpFkRMSSN/IcgaWaNdZbbHrQ9eETlecEAtM+4w257qqSHJN0YEQfHu15ErIyIgYgY6NOkRnoE0ALjCrvtPo0E/d6IeLhavM/27Ko+W9L+9rQIoBXqDr3ZtqR7JO2MiC+NKq2TtEzS7dXt2rZ0iLaK915SrK+74h/qvEL5a6rewCBNrxjPOPsCSR+XtM32lmrZLRoJ+YO2r5P0A0nXtKdFAK1QN+wR8W1JrlFe1Np2ALQLl8sCSRB2IAnCDiRB2IEkCDuQBF9xTW7/e6YU6xeeXh5HL03JLEmnvx4n3BPagyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtyr59bHgevN45+x4F5xfqMu797wj2hPTiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMn97GrNja1/qq1v1OszxXj7L2CIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDGe+dnnSPqGpPMkDUtaGRFfsX2bpD+V9Gr11Fsi4tF2NYr2eOjF/mL9szO2dagTtNt4Lqo5KummiNhs+yxJT9peX9W+HBF/2772ALTKeOZnH5I0VN0/ZHunpPPb3RiA1jqh9+y250q6VNKmatH1trfaXmV7Wo11ltsetD14RIebahZA48YddttTJT0k6caIOCjpLklvl9SvkSP/F8daLyJWRsRARAz0aVILWgbQiHGF3XafRoJ+b0Q8LEkRsS8ijkXEsKS7Jc1vX5sAmlU37LYt6R5JOyPiS6OWzx71tKslbW99ewBaZTyfxi+Q9HFJ22xvqZbdImmp7X5JIWm3pE+2pUO0VWyYXqzfcsEVxfqswWOtbAdtNJ5P478tyWOUGFMHTiJcQQckQdiBJAg7kARhB5Ig7EAShB1IwhHlKXtb6WxPjyu8qGPbA7LZFBt0MA6MNVTOkR3IgrADSRB2IAnCDiRB2IEkCDuQBGEHkujoOLvtVyXtGbXoXEk/7FgDJ6ZXe+vVviR6a1Qre3tbRPziWIWOhv0tG7cHI2Kgaw0U9GpvvdqXRG+N6lRvnMYDSRB2IIluh31ll7df0qu99WpfEr01qiO9dfU9O4DO6faRHUCHEHYgia6E3faVtp+x/Zztm7vRQy22d9veZnuL7cEu97LK9n7b20ctm257ve1nq9sx59jrUm+32X652ndbbC/uUm9zbG+0vdP2DtufrpZ3dd8V+urIfuv4e3bbEyT9t6TflbRX0hOSlkbE0x1tpAbbuyUNRETXL8Cw/duSfiLpGxHxa9Wyv5Z0ICJur/6jnBYRn+uR3m6T9JNuT+NdzVY0e/Q045KukvQJdXHfFfr6A3Vgv3XjyD5f0nMR8UJEvCHpAUlLutBHz4uIxyUdOG7xEkmrq/urNfKPpeNq9NYTImIoIjZX9w9JenOa8a7uu0JfHdGNsJ8v6aVRj/eqt+Z7D0mP2X7S9vJuNzOGWRExJI3845E0s8v9HK/uNN6ddNw04z2z7xqZ/rxZ3Qj7WL+P1Uvjfwsi4jJJH5b0qep0FeMzrmm8O2WMacZ7QqPTnzerG2HfK2nOqMcXSHqlC32MKSJeqW73S1qj3puKet+bM+hWt/u73M//66VpvMeaZlw9sO+6Of15N8L+hKSLbF9oe6KkayWt60Ifb2F7SvXBiWxPkfQh9d5U1OskLavuL5O0tou9/Jxemca71jTj6vK+6/r05xHR8T9JizXyifzzkm7tRg81+voVSd+v/nZ0uzdJ92vktO6IRs6IrpM0Q9IGSc9Wt9N7qLdvStomaatGgjW7S739lkbeGm6VtKX6W9ztfVfoqyP7jctlgSS4gg5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkvg//84QbgV8kyIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_NO=12\n",
    "plt.imshow(X = x_test[IMG_NO].reshape(HEIGHT, WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model.\n",
    "Let's start with a very simple linear classifier. All our models will have this basic interface -- they will take an image and return probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build keras model using keras Sequential API\n",
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[HEIGHT, WIDTH],\n",
    "        name='image'\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name='probabilities'\n",
    "    ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Input Functions\n",
    "As usual, we need to specify input functions for training, evaluation, and predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training input function\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'image': x_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True,\n",
    "    queue_capacity=5000\n",
    ")\n",
    "\n",
    "# Create evaluation input function\n",
    "eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'image': x_test},\n",
    "    y=y_test,\n",
    "    batch_size=100,\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    queue_capacity=5000\n",
    ")\n",
    "\n",
    "# Create serving input function for inference\n",
    "def serving_input_fn():\n",
    "    placeholder = {\n",
    "        'image': tf.compat.v1.placeholder(dtype= tf.float32, shape=[None, HEIGHT, WIDTH])\n",
    "    }\n",
    "    features = placeholder # As -is\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features,\n",
    "        receiver_tensors=placeholder\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train_and_evaluate function\n",
    "tf.estimator.train_and_evaluate does distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "    \n",
    "    # Build keras model\n",
    "    model = linear_model()\n",
    "    \n",
    "    # Compile Keras model with optimizer, loss function and eval metric\n",
    "    model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss = 'categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Convert Keras model to an estimator\n",
    "    estimator = tf.keras.estimator.model_to_estimator(\n",
    "        keras_model=model,\n",
    "        model_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # Set estimator's train_spec to use train_input_fn() and train for so many step\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=train_input_fn,\n",
    "        max_steps=hparams['train_steps']\n",
    "    )\n",
    "    \n",
    "    # Create exporter that use serving_input_fn() to create saved_model for serving\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name='exporter',\n",
    "        serving_input_receiver_fn=serving_input_fn\n",
    "    )\n",
    "    \n",
    "    # Set estimators eval_spec to use eval_input_fn() and export saved_model\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=eval_input_fn,\n",
    "        steps=None,\n",
    "        exporters=exporter\n",
    "    )\n",
    "    \n",
    "    # Run train_and_evaluate loop\n",
    "    tf.estimator.train_and_evaluate(estimator,train_spec,eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = 'mnist/learned'\n",
    "shutil.rmtree(path=OUTDIR, ignore_errors=True)\n",
    "hparams = {\n",
    "    'train_steps': 10000,\n",
    "    'learning_rate': 0.01\n",
    "}\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
