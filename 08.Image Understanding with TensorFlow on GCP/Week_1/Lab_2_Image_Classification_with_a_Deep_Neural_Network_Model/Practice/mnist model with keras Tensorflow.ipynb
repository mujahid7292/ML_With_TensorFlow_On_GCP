{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST image classification with Keras Tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"ml-practice-260405\" # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"bucket-ml-practice-260405\" # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "MODEL_TYPE = \"dnn\"  # \"linear\", \"dnn\", \"dnn_dropout\", or \"cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change \n",
    "os.environ[\"ACCOUNT\"] = \"sandcorp2014@gmail.com\"\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"MODEL_TYPE\"] = MODEL_TYPE\n",
    "os.environ[\"TFVERSION\"] = \"1.13\"  # Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/account].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set account $ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir mnistmodel_keras_tf\n",
    "mkdir mnistmodel_keras_tf/trainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnistmodel_keras_tf/trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnistmodel_keras_tf/trainer/__init__.py\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnistmodel_keras_tf/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnistmodel_keras_tf/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from .import model\n",
    "import tensorflow as tf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a parser object\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Input argument in the parser object\n",
    "    parser.add_argument(\n",
    "        \"--train_batch_size\",\n",
    "        help=\"Batch size for training\",\n",
    "        type = int,\n",
    "        default=100\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        help=\"Initial Learning Rate For Training\",\n",
    "        type=float,\n",
    "        default=0.01\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--train_steps\",\n",
    "        help=\"Steps to run the training jobs for\",\n",
    "        type=int,\n",
    "        default=0\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help=\"Local Or GCS location to write checkpoint and export model\",\n",
    "        required=True\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--job-dir\",\n",
    "        help = \"this model ignores this field, but it is required by gcloud\",\n",
    "        default = \"junk\"\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    hparams = args.__dict__\n",
    "\n",
    "    # unused args provided by service\n",
    "    hparams.pop(\"job_dir\", None)\n",
    "    hparams.pop(\"job-dir\", None)\n",
    "\n",
    "    output_dir = hparams.pop(\"output_dir\")\n",
    "    # Append trial_id to path so hptuning jobs don\"t overwrite eachother\n",
    "    output_dir = os.path.join(\n",
    "        output_dir,\n",
    "        json.loads(\n",
    "            os.environ.get(\"TF_CONFIG\", \"{}\")\n",
    "        ).get(\"task\", {}).get(\"trial\", \"\")\n",
    "    )\n",
    "    \n",
    "    # Run the training job\n",
    "    model.train_and_evaluate(output_dir, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnistmodel_keras_tf/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnistmodel_keras_tf/trainer/model.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "HEIGHT=28\n",
    "WIDTH=28\n",
    "NCLASSES=10\n",
    "\n",
    "# Build Keras model using Keras Sequential API\n",
    "def dnn_model(hparams):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[HEIGHT, WIDTH, 1], name=\"image\"))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=300, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(units=100, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(units=30, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(units=NCLASSES, activation=tf.nn.softmax, name='Probabilities'))\n",
    "    return model\n",
    "\n",
    "# Create serving input function for inference\n",
    "def serving_input_fn():\n",
    "    # Input will be rank 3\n",
    "    feature_placeholders = {\n",
    "        \"image\": tf.compat.v1.placeholder(dtype = tf.float32, shape=[None, HEIGHT, WIDTH])\n",
    "    }\n",
    "    # But model function require rank 4\n",
    "    features = {\n",
    "        \"image\": tf.expand_dims(input=feature_placeholders[\"image\"], axis=-1)\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features,\n",
    "        receiver_tensors=feature_placeholders\n",
    "    )\n",
    "\n",
    "# Create train and evaluate function\n",
    "def train_and_evaluate(ouput_dir, hparams):\n",
    "    # Ensure filewriter cache is clear for TensorBoard event file.\n",
    "    tf.compat.v1.summary.FileWriterCache.clear()\n",
    "    \n",
    "    EVAL_INTERVAL = 60\n",
    "    \n",
    "    # Get mnist Data\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Scale our training and testing features between 0 and 1\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    \n",
    "    # Reshape image to add a dimension for channels (1 in this case)\n",
    "    x_train = x_train.reshape([-1, HEIGHT, WIDTH, 1])\n",
    "    x_test = x_test.reshape([-1, HEIGHT, WIDTH, 1])\n",
    "    \n",
    "    # Convert labels to categorical one hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y=y_train, num_classes=NCLASSES)\n",
    "    y_test = tf.keras.utils.to_categorical(y=y_test, num_classes=NCLASSES)\n",
    "    \n",
    "    # Create training input function\n",
    "    train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "        x={\"image\": x_train},\n",
    "        y=y_train,\n",
    "        batch_size=100,\n",
    "        num_epochs=None,\n",
    "        shuffle=True,\n",
    "        queue_capacity=5000\n",
    "    )\n",
    "    \n",
    "    # Create evaluation input function\n",
    "    eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "        x={\"image\": x_test},\n",
    "        y=y_test,\n",
    "        batch_size=100,\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "        queue_capacity=5000\n",
    "    )\n",
    "    \n",
    "    # Build Keras model\n",
    "    model = dnn_model(hparams=hparams)\n",
    "    \n",
    "    # Compile Keras model with optimizer, loss function and eval metric\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Convert Keras model to estimator\n",
    "    estimator = tf.keras.estimator.model_to_estimator(\n",
    "        keras_model=model,\n",
    "        model_dir=ouput_dir,\n",
    "        config=tf.estimator.RunConfig(save_checkpoints_secs=EVAL_INTERVAL)\n",
    "    )\n",
    "    \n",
    "    # Set estimator's train_spec to use train_input_fn() and train for so many steps\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=train_input_fn,\n",
    "        max_steps=hparams['train_steps']\n",
    "    )\n",
    "    \n",
    "    # Create exporter that use serving_input_fn() to create saved_model for serving\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name='exporter',\n",
    "        serving_input_receiver_fn=serving_input_fn\n",
    "    )\n",
    "    \n",
    "    # Set estimators eval_spec to use eval_input_fn() and export saved_model\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=eval_input_fn,\n",
    "        steps=None,\n",
    "        exporters=exporter,\n",
    "        throttle_secs=EVAL_INTERVAL\n",
    "    )\n",
    "    \n",
    "    # Run train_and_evaluate loop\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator,\n",
    "        train_spec=train_spec,\n",
    "        eval_spec=eval_spec\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a Python module\n",
    "\n",
    "Since we want to run our code on Cloud ML Engine, we've packaged it as a python module.\n",
    "\n",
    "The `model.py` and `task.py` containing the model code is in <a href=\"mnistmodel_keras_tf/trainer\">mnistmodel_keras_tf/trainer</a>\n",
    "\n",
    "**Let's first run it locally for a few steps to test the code.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "2020-06-23 11:38:38.694087: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-06-23 11:38:38.694149: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-06-23 11:38:38.694157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 11:38:39.775887 140009068603200 module_wrapper.py:138] From /media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/08.Image Understanding with TensorFlow on GCP/Week_1/Lab_2_Image_Classification_with_a_Deep_Neural_Network_Model/Practice/mnistmodel_keras_tf/trainer/model.py:62: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "W0623 11:38:39.776058 140009068603200 module_wrapper.py:138] From /media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/08.Image Understanding with TensorFlow on GCP/Week_1/Lab_2_Image_Classification_with_a_Deep_Neural_Network_Model/Practice/mnistmodel_keras_tf/trainer/model.py:62: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n",
      "2020-06-23 11:38:39.785117: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-06-23 11:38:39.785144: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-06-23 11:38:39.785157: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mujahid7292-HP-ENVY-Notebook): /proc/driver/nvidia/version does not exist\n",
      "2020-06-23 11:38:39.785291: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-06-23 11:38:39.806892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
      "2020-06-23 11:38:39.807064: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557a45a367f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-23 11:38:39.807077: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "I0623 11:38:39.848789 140009068603200 run_config.py:535] TF_CONFIG environment variable: {'environment': 'cloud', 'cluster': {}, 'job': {'args': ['--output_dir=./mnist_keras_tf_trained', '--train_steps=100', '--learning_rate=0.01', '--job-dir', 'JOB_DIR'], 'job_name': 'trainer.task'}, 'task': {}}\n",
      "I0623 11:38:39.849524 140009068603200 keras.py:540] Using the Keras model provided.\n",
      "W0623 11:38:39.854485 140009068603200 deprecation.py:506] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "I0623 11:38:40.173244 140009068603200 estimator.py:216] Using config: {'_model_dir': './mnist_keras_tf_trained/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 60, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0623 11:38:40.173679 140009068603200 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0623 11:38:40.173813 140009068603200 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0623 11:38:40.173972 140009068603200 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 60.\n",
      "W0623 11:38:40.176802 140009068603200 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0623 11:38:40.188033 140009068603200 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0623 11:38:40.188597 140009068603200 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0623 11:38:40.192065 140009068603200 estimator.py:1151] Calling model_fn.\n",
      "I0623 11:38:40.368157 140009068603200 estimator.py:1153] Done calling model_fn.\n",
      "I0623 11:38:40.368306 140009068603200 estimator.py:1372] Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./mnist_keras_tf_trained/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "I0623 11:38:40.368368 140009068603200 warm_starting_util.py:464] Warm-starting from: ./mnist_keras_tf_trained/keras/keras_model.ckpt\n",
      "I0623 11:38:40.368416 140009068603200 warm_starting_util.py:343] Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "I0623 11:38:40.383048 140009068603200 warm_starting_util.py:538] Warm-started 8 variables.\n",
      "I0623 11:38:40.383692 140009068603200 basic_session_run_hooks.py:546] Create CheckpointSaverHook.\n",
      "I0623 11:38:40.446683 140009068603200 monitored_session.py:246] Graph was finalized.\n",
      "I0623 11:38:40.521140 140009068603200 session_manager.py:504] Running local_init_op.\n",
      "I0623 11:38:40.529388 140009068603200 session_manager.py:507] Done running local_init_op.\n",
      "W0623 11:38:40.559166 140009068603200 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0623 11:38:40.712372 140009068603200 basic_session_run_hooks.py:613] Saving checkpoints for 0 into ./mnist_keras_tf_trained/model.ckpt.\n",
      "I0623 11:38:40.860831 140009068603200 basic_session_run_hooks.py:262] loss = 2.3082473, step = 0\n",
      "I0623 11:38:41.202334 140009068603200 basic_session_run_hooks.py:613] Saving checkpoints for 100 into ./mnist_keras_tf_trained/model.ckpt.\n",
      "I0623 11:38:41.253823 140009068603200 estimator.py:1151] Calling model_fn.\n",
      "I0623 11:38:41.335223 140009068603200 estimator.py:1153] Done calling model_fn.\n",
      "I0623 11:38:41.347471 140009068603200 evaluation.py:255] Starting evaluation at 2020-06-23T11:38:41Z\n",
      "I0623 11:38:41.379473 140009068603200 monitored_session.py:246] Graph was finalized.\n",
      "I0623 11:38:41.380736 140009068603200 saver.py:1284] Restoring parameters from ./mnist_keras_tf_trained/model.ckpt-100\n",
      "I0623 11:38:41.411538 140009068603200 session_manager.py:504] Running local_init_op.\n",
      "I0623 11:38:41.420370 140009068603200 session_manager.py:507] Done running local_init_op.\n",
      "I0623 11:38:41.662097 140009068603200 evaluation.py:273] Inference Time : 0.31452s\n",
      "I0623 11:38:41.662522 140009068603200 evaluation.py:276] Finished evaluation at 2020-06-23-11:38:41\n",
      "I0623 11:38:41.662608 140009068603200 estimator.py:2053] Saving dict for global step 100: accuracy = 0.9108, global_step = 100, loss = 0.30853185\n",
      "I0623 11:38:41.684795 140009068603200 estimator.py:2113] Saving 'checkpoint_path' summary for global step 100: ./mnist_keras_tf_trained/model.ckpt-100\n",
      "I0623 11:38:41.689247 140009068603200 estimator.py:1151] Calling model_fn.\n",
      "I0623 11:38:41.802502 140009068603200 estimator.py:1153] Done calling model_fn.\n",
      "W0623 11:38:41.802683 140009068603200 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "I0623 11:38:41.802863 140009068603200 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
      "I0623 11:38:41.802917 140009068603200 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
      "I0623 11:38:41.802960 140009068603200 export_utils.py:170] Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "I0623 11:38:41.802998 140009068603200 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
      "I0623 11:38:41.803032 140009068603200 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
      "I0623 11:38:41.805175 140009068603200 saver.py:1284] Restoring parameters from ./mnist_keras_tf_trained/model.ckpt-100\n",
      "I0623 11:38:41.819862 140009068603200 builder_impl.py:666] Assets added to graph.\n",
      "I0623 11:38:41.819968 140009068603200 builder_impl.py:461] No assets to write.\n",
      "I0623 11:38:41.853970 140009068603200 builder_impl.py:426] SavedModel written to: ./mnist_keras_tf_trained/export/exporter/temp-b'1592890721'/saved_model.pb\n",
      "I0623 11:38:41.892624 140009068603200 estimator.py:375] Loss for final step: 0.4803467.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf mnistmodel_keras_tf.tar.gz mnist_keras_tf_trained\n",
    "JOB_DIR=./tmp\n",
    "gcloud ml-engine local train \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=./mnistmodel_keras_tf/trainer \\\n",
    "    --job-dir=JOB_DIR \\\n",
    "    -- \\\n",
    "    --output_dir=./mnist_keras_tf_trained \\\n",
    "    --train_steps=100 \\\n",
    "    --learning_rate=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p style='color:red'>Loss for final step: 0.23213314</p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run as python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-23 11:38:53.639599: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-06-23 11:38:53.639663: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-06-23 11:38:53.639669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 11:38:55.200824 139890367465280 module_wrapper.py:138] From /media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/08.Image Understanding with TensorFlow on GCP/Week_1/Lab_2_Image_Classification_with_a_Deep_Neural_Network_Model/Practice/mnistmodel_keras_tf/trainer/model.py:62: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "W0623 11:38:55.201011 139890367465280 module_wrapper.py:138] From /media/mujahid7292/Data/GoogleDriveSandCorp2014/ML_With_TensorFlow_On_GCP/08.Image Understanding with TensorFlow on GCP/Week_1/Lab_2_Image_Classification_with_a_Deep_Neural_Network_Model/Practice/mnistmodel_keras_tf/trainer/model.py:62: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n",
      "2020-06-23 11:38:55.210261: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-06-23 11:38:55.210343: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-06-23 11:38:55.210388: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mujahid7292-HP-ENVY-Notebook): /proc/driver/nvidia/version does not exist\n",
      "2020-06-23 11:38:55.210593: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-06-23 11:38:55.234977: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
      "2020-06-23 11:38:55.235367: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555c9347f010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-23 11:38:55.235408: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "I0623 11:38:55.288847 139890367465280 keras.py:540] Using the Keras model provided.\n",
      "W0623 11:38:55.402294 139890367465280 deprecation.py:506] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "I0623 11:38:55.745814 139890367465280 estimator.py:216] Using config: {'_model_dir': './mnist_keras_tf_trained/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 60, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0623 11:38:55.746226 139890367465280 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0623 11:38:55.746345 139890367465280 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0623 11:38:55.746493 139890367465280 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 60.\n",
      "W0623 11:38:55.749282 139890367465280 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0623 11:38:55.760525 139890367465280 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0623 11:38:55.761082 139890367465280 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0623 11:38:55.764548 139890367465280 estimator.py:1151] Calling model_fn.\n",
      "I0623 11:38:55.940016 139890367465280 estimator.py:1153] Done calling model_fn.\n",
      "I0623 11:38:55.940159 139890367465280 estimator.py:1372] Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./mnist_keras_tf_trained/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "I0623 11:38:55.940210 139890367465280 warm_starting_util.py:464] Warm-starting from: ./mnist_keras_tf_trained/keras/keras_model.ckpt\n",
      "I0623 11:38:55.940246 139890367465280 warm_starting_util.py:343] Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "I0623 11:38:55.954955 139890367465280 warm_starting_util.py:538] Warm-started 8 variables.\n",
      "I0623 11:38:55.955591 139890367465280 basic_session_run_hooks.py:546] Create CheckpointSaverHook.\n",
      "I0623 11:38:56.018128 139890367465280 monitored_session.py:246] Graph was finalized.\n",
      "I0623 11:38:56.093025 139890367465280 session_manager.py:504] Running local_init_op.\n",
      "I0623 11:38:56.101242 139890367465280 session_manager.py:507] Done running local_init_op.\n",
      "W0623 11:38:56.130971 139890367465280 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0623 11:38:56.284527 139890367465280 basic_session_run_hooks.py:613] Saving checkpoints for 0 into ./mnist_keras_tf_trained/model.ckpt.\n",
      "I0623 11:38:56.454716 139890367465280 basic_session_run_hooks.py:262] loss = 2.356863, step = 0\n",
      "I0623 11:38:56.811562 139890367465280 basic_session_run_hooks.py:613] Saving checkpoints for 100 into ./mnist_keras_tf_trained/model.ckpt.\n",
      "I0623 11:38:56.862154 139890367465280 estimator.py:1151] Calling model_fn.\n",
      "I0623 11:38:56.943932 139890367465280 estimator.py:1153] Done calling model_fn.\n",
      "I0623 11:38:56.956223 139890367465280 evaluation.py:255] Starting evaluation at 2020-06-23T11:38:56Z\n",
      "I0623 11:38:56.980773 139890367465280 monitored_session.py:246] Graph was finalized.\n",
      "I0623 11:38:56.981936 139890367465280 saver.py:1284] Restoring parameters from ./mnist_keras_tf_trained/model.ckpt-100\n",
      "I0623 11:38:57.010244 139890367465280 session_manager.py:504] Running local_init_op.\n",
      "I0623 11:38:57.018785 139890367465280 session_manager.py:507] Done running local_init_op.\n",
      "I0623 11:38:57.249719 139890367465280 evaluation.py:273] Inference Time : 0.29339s\n",
      "I0623 11:38:57.250158 139890367465280 evaluation.py:276] Finished evaluation at 2020-06-23-11:38:57\n",
      "I0623 11:38:57.250253 139890367465280 estimator.py:2053] Saving dict for global step 100: accuracy = 0.9205, global_step = 100, loss = 0.2784722\n",
      "I0623 11:38:57.272400 139890367465280 estimator.py:2113] Saving 'checkpoint_path' summary for global step 100: ./mnist_keras_tf_trained/model.ckpt-100\n",
      "I0623 11:38:57.276839 139890367465280 estimator.py:1151] Calling model_fn.\n",
      "I0623 11:38:57.386357 139890367465280 estimator.py:1153] Done calling model_fn.\n",
      "W0623 11:38:57.386544 139890367465280 deprecation.py:323] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "I0623 11:38:57.386734 139890367465280 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
      "I0623 11:38:57.386794 139890367465280 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
      "I0623 11:38:57.386855 139890367465280 export_utils.py:170] Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "I0623 11:38:57.386909 139890367465280 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
      "I0623 11:38:57.386957 139890367465280 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
      "I0623 11:38:57.389019 139890367465280 saver.py:1284] Restoring parameters from ./mnist_keras_tf_trained/model.ckpt-100\n",
      "I0623 11:38:57.403405 139890367465280 builder_impl.py:666] Assets added to graph.\n",
      "I0623 11:38:57.403510 139890367465280 builder_impl.py:461] No assets to write.\n",
      "I0623 11:38:57.440335 139890367465280 builder_impl.py:426] SavedModel written to: ./mnist_keras_tf_trained/export/exporter/temp-b'1592890737'/saved_model.pb\n",
      "I0623 11:38:57.479180 139890367465280 estimator.py:375] Loss for final step: 0.28325686.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf mnistmodel_keras_tf.tar.gz mnist_keras_tf_trained\n",
    "python3 -m mnistmodel_keras_tf.trainer.task \\\n",
    "    --learning_rate=0.01 \\\n",
    "    --train_steps=100 \\\n",
    "    --output_dir=./mnist_keras_tf_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p style='color:red'>Loss for final step: 0.2467457</p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's do it on Cloud ML Engine so we can train on GPU (`--scale-tier=BASIC_GPU`)**\n",
    "\n",
    "Note the GPU speed up depends on the model type. You'll notice the more complex CNN model trains significantly faster on GPU, however the speed up on the simpler models is not as pronounced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://bucket-ml-practice-260405/mnist/trained_dnn us-central1 mnist_dnn_200623_043818\n",
      "jobId: mnist_dnn_200623_043818\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "Job [mnist_dnn_200623_043818] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe mnist_dnn_200623_043818\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs mnist_dnn_200623_043818\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/mnist/trained_dnn\n",
    "JOBNAME=mnist_dnn_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=./mnistmodel_keras_tf/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=BASIC_GPU \\\n",
    "    --runtime-version=$TFVERSION \\\n",
    "    -- \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --train_steps=100 \\\n",
    "    --learning_rate=0.01 \\\n",
    "    --train_batch_size=512 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p style='color:red'>Loss for final step: 0.19776809</p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying mnist dnn from gs://bucket-ml-practice-260405/mnist/trained_dnn/export/exporter/1592887244/ ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 0623 10:50:57.387782 retry_util.py] Retrying request, attempt #1...\n",
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "WARNING: Using endpoint [https://ml.googleapis.com/]\n",
      "Created ml engine model [projects/ml-practice-260405/models/mnist].\n",
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "WARNING: Using endpoint [https://ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......\n",
      "........................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"mnist\"\n",
    "MODEL_VERSION=${MODEL_TYPE}\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/mnist/trained_${MODEL_TYPE}/export/exporter | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, let's take one of the example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "\n",
    "# Get mnist data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(_, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# Scale our features between 0 and 1\n",
    "x_test = x_test / 255.0 \n",
    "\n",
    "IMGNO = 5 # CHANGE THIS to get different images\n",
    "jsondata = {\"image\": x_test[IMGNO].reshape(HEIGHT, WIDTH).tolist()}\n",
    "json.dump(jsondata, codecs.open(\"test.json\", 'w', encoding = \"utf-8\"))\n",
    "plt.imshow(x_test[IMGNO].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send it to the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBABILITIES\n",
      "[1.8366279618931003e-05, 0.9959606528282166, 0.0004146232095081359, 5.972717553959228e-05, 3.9062806536094286e-06, 0.000798432738520205, 7.479923078790307e-05, 0.001814400078728795, 0.000790452235378325, 6.461288285208866e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using endpoint [https://ml.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform predict \\\n",
    "    --model=mnist \\\n",
    "    --version=${MODEL_TYPE} \\\n",
    "    --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Trained Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf mnistmodel_keras_tf.tar.gz mnist_keras_tf_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
