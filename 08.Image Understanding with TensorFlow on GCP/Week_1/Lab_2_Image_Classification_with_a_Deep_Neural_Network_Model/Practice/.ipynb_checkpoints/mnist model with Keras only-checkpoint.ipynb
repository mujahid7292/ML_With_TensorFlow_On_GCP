{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST image classification with Keras only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"ml-practice-260405\" # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"bucket-ml-practice-260405\" # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "MODEL_TYPE = \"dnn\"  # \"linear\", \"dnn\", \"dnn_dropout\", or \"cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change \n",
    "os.environ[\"ACCOUNT\"] = \"sandcorp2014@gmail.com\"\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"MODEL_TYPE\"] = MODEL_TYPE\n",
    "os.environ[\"TFVERSION\"] = \"2.1.0\"  # Tensorflow version\n",
    "os.environ[\"IMAGE_URI\"] = os.path.join(\"gcr.io\", PROJECT, \"mnistmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/account].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set account $ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir mnistmodel_keras_only\n",
    "mkdir mnistmodel_keras_only/trainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnistmodel_keras_only/trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnistmodel_keras_only/trainer/__init__.py\n",
    "# Empty file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnistmodel_keras_only/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnistmodel_keras_only/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from . import model\n",
    "\n",
    "def _parse_arguments(argv):\n",
    "    \"\"\"\n",
    "    Parse command line arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--model_type',\n",
    "        help=\"Which model type to use.\",\n",
    "        type=str,\n",
    "        default='dnn'\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        help='The number of epochs to train.',\n",
    "        type=int,\n",
    "        default=10\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--steps_per_epoch',\n",
    "        help='The number of steps per epoch to train.',\n",
    "        type=int,\n",
    "        default=100\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help=\"Directory where to save the model.\",\n",
    "        type=str,\n",
    "        default='mnistmodel_keras_only/'\n",
    "    )\n",
    "    \n",
    "    return parser.parse_known_args(argv)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Parse command line arguments and kicks off model training.\n",
    "    \"\"\"\n",
    "    args = _parse_arguments(sys.argv[1:])[0]\n",
    "    \n",
    "    model_layers = model.get_layers(args.model_type)\n",
    "    \n",
    "    image_model = model.build_model(model_layers, args.job_dir)\n",
    "    \n",
    "    model_history = model.train_and_evaluate(\n",
    "        image_model, args.epochs, args.steps_per_epoch, args.job_dir\n",
    "    )\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's group non-model functions into a util file to keep the model file simple. We'll copy over the `scale` and `load_dataset` functions from the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnistmodel_keras_only/trainer/util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnistmodel_keras_only/trainer/util.py\n",
    "import tensorflow as tf\n",
    "\n",
    "def scale(image, label):\n",
    "    \"\"\"\n",
    "    Scale image from 0 to 255 int range to a 0.0 to 1.0 float range\n",
    "    \"\"\"\n",
    "    image = tf.cast(x=image, dtype=tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.expand_dims(input=image, axis=-1)\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(data, training=True, buffer_size=5000, batch_size=100, nclasses=10):\n",
    "    \"\"\"\n",
    "    Loads MNIST dataset into a tf.data.Dataset\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    \n",
    "    x = x_train if training else x_test\n",
    "    y = y_train if training else y_test\n",
    "    \n",
    "    # One-hot encode the class\n",
    "    y = tf.keras.utils.to_categorical(y = y, num_classes=nclasses)\n",
    "    \n",
    "    # Convert our data into tf.data\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset = dataset.map(scale).batch(batch_size)\n",
    "    \n",
    "    # During training shuffle our dataset\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size).repeat()\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's code the models! The [tf.keras API](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras) accepts an array of [layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) into a [model object](https://www.tensorflow.org/api_docs/python/tf/keras/Model), so we can create a dictionary of layers based on the different model types we want to use. The below file has two functions: `get_layers` and `create_and_train_model`. We will build the structure of our model in `get_layers`. Last but not least, we'll copy over the training code from the previous lab into `train_and_evaluate`.\n",
    "\n",
    "These models progressively build on each other. Look at the imported `tensorflow.keras.layers` modules and the default values for the variables defined in `get_layers` for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnistmodel_keras_only/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnistmodel_keras_only/trainer/model.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten,\n",
    "                                     MaxPooling2D, Softmax)\n",
    "\n",
    "from . import util\n",
    "\n",
    "# Image Variables\n",
    "WIDTH = 28\n",
    "HEIGHT = 28\n",
    "\n",
    "def get_layers(model_type, nclasses = 10, hidden_layer_1_neurons=400,\n",
    "              hidden_layer_2_neurons=100):\n",
    "    \"\"\"\n",
    "    Construct layers for keras model based on a dict of model types.\n",
    "    \"\"\"\n",
    "    model_layers = {\n",
    "        'linear':[\n",
    "            Flatten(),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn':[\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return model_layers[model_type]\n",
    "\n",
    "def build_model(layers, output_dir):\n",
    "    \"\"\"\n",
    "    Compiles keras model for image classification.\n",
    "    \"\"\"\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model, num_epochs, steps_per_epoch, output_dir):\n",
    "    \"\"\"\n",
    "    Compiles keras model and loads data into it for training.\n",
    "    \"\"\"\n",
    "    # Load MNIST dataset\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Spilt dataset into train and validation.\n",
    "    train_data = util.load_dataset(mnist)\n",
    "    validation_data = util.load_dataset(mnist, training=False)\n",
    "    \n",
    "    # Create TensorBoard callback\n",
    "    callbacks = []\n",
    "    if output_dir:\n",
    "        tensorboard_callback = TensorBoard(log_dir=output_dir)\n",
    "        callbacks = [tensorboard_callback]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=validation_data,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Now save the trained model\n",
    "    if output_dir:\n",
    "        export_path = os.path.join(output_dir, 'keras_export')\n",
    "        model.save(export_path, save_format='tf')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a Python module\n",
    "\n",
    "Since we want to run our code on Cloud ML Engine, we've packaged it as a python module.\n",
    "\n",
    "The `model.py` and `task.py` containing the model code is in <a href=\"mnistmodel_keras_only/trainer\">mnistmodel_keras_only/trainer</a>\n",
    "\n",
    "**Let's first run it locally for a few steps to test the code.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 3s - loss: 0.8095 - accuracy: 0.7768 - val_loss: 0.3892 - val_accuracy: 0.8829\n",
      "Epoch 2/5\n",
      "50/50 - 1s - loss: 0.3459 - accuracy: 0.8936 - val_loss: 0.2922 - val_accuracy: 0.9121\n",
      "Epoch 3/5\n",
      "50/50 - 1s - loss: 0.2650 - accuracy: 0.9208 - val_loss: 0.2329 - val_accuracy: 0.9291\n",
      "Epoch 4/5\n",
      "50/50 - 1s - loss: 0.2520 - accuracy: 0.9286 - val_loss: 0.2080 - val_accuracy: 0.9399\n",
      "Epoch 5/5\n",
      "50/50 - 1s - loss: 0.2035 - accuracy: 0.9396 - val_loss: 0.1881 - val_accuracy: 0.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-25 12:23:58.912648: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-06-25 12:23:58.912713: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-06-25 12:23:58.912720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-06-25 12:23:59.857152: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-06-25 12:23:59.857177: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-06-25 12:23:59.857189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mujahid7292-HP-ENVY-Notebook): /proc/driver/nvidia/version does not exist\n",
      "2020-06-25 12:23:59.857352: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-06-25 12:23:59.878448: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
      "2020-06-25 12:23:59.878714: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558f169bd5b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-25 12:23:59.878736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-06-25 12:24:03.842122: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2020-06-25 12:24:03.842293: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory\n",
      "2020-06-25 12:24:03.842306: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2020-06-25 12:24:03.842312: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2020-06-25 12:24:03.846170: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2020-06-25 12:24:03.846203: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.\n",
      "2020-06-25 12:24:06.984417: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0625 12:24:07.041129 139990703998784 deprecation.py:506] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_TYPE='dnn'\n",
    "JOB_DIR='mnistmodel_keras_only'\n",
    "rm -rf mnistmodel_keras_only.tar.gz mnist_keras_only_trained\n",
    "python3 -m mnistmodel_keras_only.trainer.task \\\n",
    "    --job-dir=${JOB_DIR}\\\n",
    "    --epochs=5 \\\n",
    "    --steps_per_epoch=50 \\\n",
    "    --model_type=${MODEL_TYPE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/10\n",
      "50/50 - 3s - loss: 0.7703 - accuracy: 0.7766 - val_loss: 0.3322 - val_accuracy: 0.9076\n",
      "Epoch 2/10\n",
      "50/50 - 1s - loss: 0.3577 - accuracy: 0.8954 - val_loss: 0.2801 - val_accuracy: 0.9182\n",
      "Epoch 3/10\n",
      "50/50 - 1s - loss: 0.2713 - accuracy: 0.9204 - val_loss: 0.2451 - val_accuracy: 0.9252\n",
      "Epoch 4/10\n",
      "50/50 - 1s - loss: 0.2280 - accuracy: 0.9340 - val_loss: 0.2121 - val_accuracy: 0.9362\n",
      "Epoch 5/10\n",
      "50/50 - 1s - loss: 0.2141 - accuracy: 0.9396 - val_loss: 0.1982 - val_accuracy: 0.9380\n",
      "Epoch 6/10\n",
      "50/50 - 1s - loss: 0.2022 - accuracy: 0.9380 - val_loss: 0.1827 - val_accuracy: 0.9430\n",
      "Epoch 7/10\n",
      "50/50 - 1s - loss: 0.1573 - accuracy: 0.9528 - val_loss: 0.1673 - val_accuracy: 0.9491\n",
      "Epoch 8/10\n",
      "50/50 - 1s - loss: 0.1991 - accuracy: 0.9370 - val_loss: 0.1591 - val_accuracy: 0.9502\n",
      "Epoch 9/10\n",
      "50/50 - 1s - loss: 0.1604 - accuracy: 0.9502 - val_loss: 0.1386 - val_accuracy: 0.9586\n",
      "Epoch 10/10\n",
      "50/50 - 1s - loss: 0.1437 - accuracy: 0.9560 - val_loss: 0.1241 - val_accuracy: 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "2020-06-25 12:24:24.059087: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-06-25 12:24:24.059175: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-06-25 12:24:24.059186: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-06-25 12:24:24.944040: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-06-25 12:24:24.944063: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-06-25 12:24:24.944079: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mujahid7292-HP-ENVY-Notebook): /proc/driver/nvidia/version does not exist\n",
      "2020-06-25 12:24:24.944242: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-06-25 12:24:24.966489: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
      "2020-06-25 12:24:24.966650: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558e3b7c1b40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-25 12:24:24.966664: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-06-25 12:24:28.866879: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2020-06-25 12:24:28.867069: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory\n",
      "2020-06-25 12:24:28.867080: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2020-06-25 12:24:28.867106: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2020-06-25 12:24:28.870947: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2020-06-25 12:24:28.870982: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.\n",
      "2020-06-25 12:24:34.964758: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0625 12:24:35.021438 140075506857792 deprecation.py:506] From /home/mujahid7292/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_TYPE='dnn'\n",
    "JOB_DIR='mnistmodel_keras_only'\n",
    "rm -rf mnistmodel_keras_only.tar.gz mnist_keras_only_trained\n",
    "JOB_DIR=./tmp\n",
    "gcloud ml-engine local train \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=./mnistmodel_keras_only/trainer \\\n",
    "    -- \\\n",
    "    --job-dir=${JOB_DIR}\\\n",
    "    --epochs=10 \\\n",
    "    --steps_per_epoch=50 \\\n",
    "    --model_type=${MODEL_TYPE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's do it on Cloud ML Engine so we can train on GPU (`--scale-tier=BASIC_GPU`)**\n",
    "\n",
    "Note the GPU speed up depends on the model type. You'll notice the more complex CNN model trains significantly faster on GPU, however the speed up on the simpler models is not as pronounced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://bucket-ml-practice-260405/mnist/trained_dnn us-central1 mnist_dnn_200625_062605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "ERROR: (gcloud.ml-engine.jobs.submit.training) INVALID_ARGUMENT: Field: runtime_version Error: The specified runtime version '2.1.0' with the Python version '' is not supported or is deprecated.  Please specify a different runtime version. See https://cloud.google.com/ml-engine/docs/runtime-version-list for a list of supported versions\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: The specified runtime version '2.1.0' with the Python version ''\n",
      "      is not supported or is deprecated.  Please specify a different runtime version.\n",
      "      See https://cloud.google.com/ml-engine/docs/runtime-version-list for a list\n",
      "      of supported versions\n",
      "    field: runtime_version\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'OUTDIR=gs://${BUCKET}/mnist/trained_dnn\\nJOBNAME=mnist_dnn_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ml-engine jobs submit training $JOBNAME \\\\\\n    --region=$REGION \\\\\\n    --module-name=trainer.task \\\\\\n    --package-path=./mnistmodel_keras_only/trainer \\\\\\n    --job-dir=$OUTDIR \\\\\\n    --staging-bucket=gs://$BUCKET \\\\\\n    --scale-tier=BASIC_GPU \\\\\\n    --runtime-version=$TFVERSION \\\\\\n    -- \\\\\\n    --epochs=50 \\\\\\n    --steps_per_epoch=50 \\\\\\n    --model_type=$MODEL_TYPE\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0654efcb7c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OUTDIR=gs://${BUCKET}/mnist/trained_dnn\\nJOBNAME=mnist_dnn_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ml-engine jobs submit training $JOBNAME \\\\\\n    --region=$REGION \\\\\\n    --module-name=trainer.task \\\\\\n    --package-path=./mnistmodel_keras_only/trainer \\\\\\n    --job-dir=$OUTDIR \\\\\\n    --staging-bucket=gs://$BUCKET \\\\\\n    --scale-tier=BASIC_GPU \\\\\\n    --runtime-version=$TFVERSION \\\\\\n    -- \\\\\\n    --epochs=50 \\\\\\n    --steps_per_epoch=50 \\\\\\n    --model_type=$MODEL_TYPE\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/mujahid7292/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'OUTDIR=gs://${BUCKET}/mnist/trained_dnn\\nJOBNAME=mnist_dnn_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ml-engine jobs submit training $JOBNAME \\\\\\n    --region=$REGION \\\\\\n    --module-name=trainer.task \\\\\\n    --package-path=./mnistmodel_keras_only/trainer \\\\\\n    --job-dir=$OUTDIR \\\\\\n    --staging-bucket=gs://$BUCKET \\\\\\n    --scale-tier=BASIC_GPU \\\\\\n    --runtime-version=$TFVERSION \\\\\\n    -- \\\\\\n    --epochs=50 \\\\\\n    --steps_per_epoch=50 \\\\\\n    --model_type=$MODEL_TYPE\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/mnist/trained_dnn\n",
    "JOBNAME=mnist_dnn_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=./mnistmodel_keras_only/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=BASIC_GPU \\\n",
    "    --runtime-version=$TFVERSION \\\n",
    "    -- \\\n",
    "    --epochs=50 \\\n",
    "    --steps_per_epoch=50 \\\n",
    "    --model_type=$MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
