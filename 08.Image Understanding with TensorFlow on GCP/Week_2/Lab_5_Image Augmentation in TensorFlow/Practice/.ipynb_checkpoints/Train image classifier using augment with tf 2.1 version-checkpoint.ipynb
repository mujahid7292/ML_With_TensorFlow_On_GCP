{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"ml-practice-260405\"\n",
    "BUCKET = \"bucket-ml-practice-260405\"\n",
    "REGION = \"us-central1\"\n",
    "MODEL_TYPE = \"cnn\"  # \"linear\", \"dnn\", \"dnn_dropout\", or \"cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change \n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"MODEL_TYPE\"] = MODEL_TYPE\n",
    "os.environ[\"TFVERSION\"] = \"2.1\"  # Tensorflow version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input functions to read JPEG images\n",
    "\n",
    "The key difference between this notebook and [the MNIST one](./mnist_models.ipynb) is in the input function.\n",
    "In the input function here, we are doing the following:\n",
    "* Reading JPEG images, rather than 2D integer arrays.\n",
    "* Reading in batches of batch_size images rather than slicing our in-memory structure to be batch_size images.\n",
    "* Resizing the images to the expected HEIGHT, WIDTH. Because this is a real-world dataset, the images are of different sizes. We need to preprocess the data to, at the very least, resize them to constant size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir flowersmodel_augment_tf_v_2_1\n",
    "mkdir flowersmodel_augment_tf_v_2_1/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flowersmodel_augment_tf_v_2_1/trainer/__init__.py\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flowersmodel_augment_tf_v_2_1/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from . import model\n",
    "import tensorflow as tf\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Input Arguments\n",
    "    parser.add_argument(\n",
    "        '--batch_size',\n",
    "        help=\"Batch size for training steps.\",\n",
    "        type=int,\n",
    "        default=100\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--learning_rate',\n",
    "        help=\"Initial learning rate for training.\",\n",
    "        type=float,\n",
    "        default=0.01\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--train_steps',\n",
    "        help=\"Steps to run the train jobs for. A step is one batch size.\",\n",
    "        type=int,\n",
    "        default=100\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--output_dir',\n",
    "        help=\"GCS location to write checkpoints and export model\",\n",
    "        required=True\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--train_data_path',\n",
    "        help=\"Location of train file, which contain training image URL with appropriate label.\",\n",
    "        default=\"gs://cloud-ml-data/img/flower_photos/train_set.csv\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--eval_data_path',\n",
    "        help=\"Location of eval file, which contain evaluation image URL with appropriate label.\",\n",
    "        default=\"gs://cloud-ml-data/img/flower_photos/eval_set.csv\"\n",
    "    )\n",
    "\n",
    "    # Build list model_fn's for help message.\n",
    "    model_names = [name.replace(\"_model\", \"\") for name in dir(model) if name.endswith('_model')]\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--model',\n",
    "        help=\"Type of model. Supported types are {}\".format(model_names),\n",
    "        required=True\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help=\"This model ignore this field, but it is required by gcloud.\",\n",
    "        default='junk'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--augment',\n",
    "        help=\"If specified augment image data.\",\n",
    "        dest='augment',\n",
    "        action='store_true'\n",
    "    )\n",
    "\n",
    "    parser.set_defaults(augment=False)\n",
    "\n",
    "    # Optional hyper parameter used by cnn.\n",
    "    parser.add_argument(\n",
    "        '--ksize1',\n",
    "        help=\"Kernel size of the first layer of the cnn.\",\n",
    "        type=int,\n",
    "        default=5\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--ksize2',\n",
    "        help=\"Kernel size of the second layer of the cnn.\",\n",
    "        type=int,\n",
    "        default=5\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--nfil1',\n",
    "        help=\"Number of filters in the first layer of the cnn.\",\n",
    "        type=int,\n",
    "        default=10\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--nfil2',\n",
    "        help=\"Number of filters in the second layer of the cnn.\",\n",
    "        type=int,\n",
    "        default=20\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--dprob',\n",
    "        help=\"Dropout probability for cnn\",\n",
    "        type=float,\n",
    "        default=0.25\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--batch_norm',\n",
    "        help=\"If specified do batch norm for CNN\",\n",
    "        dest=\"batch_norm\",\n",
    "        action=\"store_true\"\n",
    "    )\n",
    "\n",
    "    parser.set_defaults(batch_norm = False)\n",
    "\n",
    "    args= parser.parse_args()\n",
    "    hparams = args.__dict__\n",
    "\n",
    "    output_dir = hparams.pop('output_dir')\n",
    "\n",
    "    # Appends trail id to path for hyper parameter tunning.\n",
    "    output_dir = os.path.join(\n",
    "        output_dir,\n",
    "        json.loads(\n",
    "            os.environ.get(\"TF_CONFIG\", \"{}\")\n",
    "        ).get(\"task\", {}).get(\"trail\", \"\")\n",
    "    )\n",
    "\n",
    "    # Run the training job.\n",
    "    model.train_and_evaluate(output_dir, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flowersmodel_augment_tf_v_2_1/trainer/model.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(\n",
    "    tf.compat.v1.logging.INFO\n",
    ")\n",
    "\n",
    "LIST_OF_LABELS = 'daisy,dandelion,roses,sunflowers,tulips'.split(',')\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "NUM_CHANNELS = 3\n",
    "NCLASSES = 5\n",
    "\n",
    "# Build Keras model using Keras Sequential API\n",
    "def linear_model(hparams):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS],\n",
    "        name=\"image\"\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name=\"probabilities\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def dnn_model(hparams):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS],\n",
    "        name=\"image\"\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=300,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=100,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=30,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name=\"probabilities\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def dnn_dropout_model(hparams):\n",
    "    dprob = hparams.get(\"dprob\", 0.10)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS],\n",
    "        name=\"image\"\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=300,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=100,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=30,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=dprob\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name=\"probabilities\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def cnn_model(hparams):\n",
    "    ksize1 = hparams.get(\"ksize1\", 5)\n",
    "    ksize2 = hparams.get(\"ksize2\", 5)\n",
    "    nfil1 = hparams.get(\"nfil1\", 10)\n",
    "    nfil2 = hparams.get(\"nfil2\", 20)\n",
    "    dprob = hparams.get(\"dprob\", 0.25)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS],\n",
    "        name=\"image\"\n",
    "    )) # Shape = (?, 224, 224, 3)\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=nfil1,\n",
    "        kernel_size=ksize1,\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )) # Shape = (?, 224, 224, nfil1)\n",
    "    model.add(tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2\n",
    "    )) # Shape = (?, 112, 112, nfil1)\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=nfil2,\n",
    "        kernel_size=ksize2,\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )) # Shape = (?, 112, 112, nfil2)\n",
    "    model.add(tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2\n",
    "    )) # Shape = (?, 56, 56, nfil2)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    # Apply batch normalization.\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=300,\n",
    "            activation=tf.nn.relu\n",
    "        ))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Activation(\n",
    "            activation=tf.nn.relu\n",
    "        ))\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=300,\n",
    "            activation=tf.nn.relu\n",
    "        ))\n",
    "    \n",
    "    # Apply Dropout\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=dprob\n",
    "    ))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=None\n",
    "    ))\n",
    "    \n",
    "    # Apply Batch Normalization once more.\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    # SoftMax Layer.\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name=\"probabilities\"\n",
    "    ))\n",
    "    \n",
    "    return model\n",
    "\n",
    "MAX_DELTA = 63.0 / 255.0 # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "def read_and_preprocess(image_bytes, label=None, augment=False):\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(\n",
    "        contents=image_bytes,\n",
    "        channels=NUM_CHANNELS\n",
    "    )\n",
    "    # Use 'convert_image_dtype' to converts to floats in the \n",
    "    # [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(\n",
    "        image=img,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    # Resize the image to a desired size.\n",
    "    img = tf.image.resize(\n",
    "        images=img,\n",
    "        size=[IMG_HEIGHT + 10, IMG_WIDTH + 10],\n",
    "    )\n",
    "    \n",
    "    if augment:\n",
    "        img = tf.image.random_crop(\n",
    "            value=img,\n",
    "            size=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS]\n",
    "        )\n",
    "        img = tf.image.random_flip_left_right(\n",
    "            image=img\n",
    "        )\n",
    "        img = tf.image.random_brightness(\n",
    "            image=img,\n",
    "            max_delta=MAX_DELTA\n",
    "        )\n",
    "        img = tf.image.random_contrast(\n",
    "            image=img,\n",
    "            lower=CONTRAST_LOWER,\n",
    "            upper=CONTRAST_UPPER\n",
    "        )\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def read_and_preprocess_with_augment(image_bytes, label=None):\n",
    "    return read_and_preprocess(\n",
    "        image_bytes=image_bytes,\n",
    "        label=label,\n",
    "        augment=True\n",
    "    )\n",
    "\n",
    "# Create Serving input function for inference.\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        \"image_bytes\":tf.compat.v1.placeholder(\n",
    "            dtype=tf.string,\n",
    "            shape=[]\n",
    "        )\n",
    "    }\n",
    "    img = read_and_preprocess(\n",
    "        image_bytes=feature_placeholders[\"image_bytes\"]\n",
    "    )\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=img,\n",
    "        receiver_tensors=feature_placeholders,\n",
    "    )\n",
    "\n",
    "def make_input_fn(csv_of_filenames, batch_size, training=True, augment=False):\n",
    "    def _input_fn():\n",
    "        def decode_csv(csv_row):\n",
    "            record_defaults = [\"path\", \"flowers\"]\n",
    "            filename, label_string = tf.io.decode_csv(\n",
    "                records=csv_row,\n",
    "                record_defaults=record_defaults\n",
    "            )\n",
    "            image_bytes = tf.io.read_file(\n",
    "                filename=filename\n",
    "            )\n",
    "            label = tf.math.equal(LIST_OF_LABELS, label_string)\n",
    "            return image_bytes, label\n",
    "        \n",
    "        # Create tf.data.dataset from filename\n",
    "        dataset = tf.data.TextLineDataset(\n",
    "            filenames=csv_of_filenames\n",
    "        ).map(decode_csv)\n",
    "        \n",
    "        if augment:\n",
    "            dataset = dataset.map(read_and_preprocess_with_augment)\n",
    "        else:\n",
    "            dataset = dataset.map(read_and_preprocess)\n",
    "            \n",
    "        if training:\n",
    "            num_epochs = None # Indefinately\n",
    "            dataset = dataset.shuffle(\n",
    "                buffer_size = 10 * batch_size\n",
    "            ) \n",
    "        else:\n",
    "            num_epochs=1 # Each photo used once\n",
    "            \n",
    "        dataset = dataset.repeat(\n",
    "            count=num_epochs\n",
    "        ).batch(batch_size=batch_size)\n",
    "        \n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    return _input_fn\n",
    "\n",
    "# Wrapper function to build selected Keras model type.\n",
    "def image_classifier(hparams):\n",
    "    model_functions = {\n",
    "        \"linear\": linear_model,\n",
    "        \"dnn\": dnn_model,\n",
    "        \"dnn_dropout\":dnn_dropout_model,\n",
    "        \"cnn\":cnn_model\n",
    "    }\n",
    "    \n",
    "    # Get function pointer for selected model type\n",
    "    model_function = model_functions[hparams[\"model\"]]\n",
    "    \n",
    "    # Build selected Keras model.\n",
    "    model = model_function(hparams)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create train_and_evaluate function.\n",
    "def train_and_evaluate(output_dir, hparams):\n",
    "    # Ensure filewriter cache is clear for TensorBoard event file.\n",
    "    tf.compat.v1.summary.FileWriterCache.clear()\n",
    "    \n",
    "    EVAL_INTERVAL = 60\n",
    "    \n",
    "    # Build Keras model.\n",
    "    model = image_classifier(hparams)\n",
    "    \n",
    "    # Compile Keras model with Optimizer, Loss Function\n",
    "    # and eval metric.\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # Convert keras model to estimator.\n",
    "    estimator = tf.keras.estimator.model_to_estimator(\n",
    "        keras_model=model,\n",
    "        model_dir=output_dir,\n",
    "        config=tf.estimator.RunConfig(\n",
    "            save_checkpoints_secs=EVAL_INTERVAL\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Set estimator train_spec\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=make_input_fn(\n",
    "            csv_of_filenames=hparams['train_data_path'],\n",
    "            batch_size=hparams['batch_size'],\n",
    "            training=True,\n",
    "            augment=hparams['augment']\n",
    "        ),\n",
    "        max_steps=hparams['train_steps']\n",
    "    )\n",
    "    \n",
    "    # Create exporter that use serving_input_fn() to\n",
    "    # create saved_model for serving.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=serving_input_fn,\n",
    "    )\n",
    "    \n",
    "    # Set estimators eval_spec.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=make_input_fn(\n",
    "            csv_of_filenames=hparams['eval_data_path'],\n",
    "            batch_size=hparams['batch_size'],\n",
    "            training=False,\n",
    "        ),\n",
    "        steps=None,\n",
    "        exporters=exporter,\n",
    "        throttle_secs=EVAL_INTERVAL\n",
    "    )\n",
    "    \n",
    "    # Run train_and_evaluate\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, \n",
    "        train_spec=train_spec, \n",
    "        eval_spec=eval_spec\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a Python module\n",
    "\n",
    "Let's first run it locally for a short while to test the code works. Note the --model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf flowersmodel.tar.gz flowers_trained\n",
    "gcloud ml-engine local train \\\n",
    "    --module-name=flowersmodel_augment_tf_v_2_1.task \\\n",
    "    --package-path=./flowersmodel_augment_tf_v_2_1 \\\n",
    "    -- \\\n",
    "    --output_dir=./flowers_trained \\\n",
    "    --train_steps=5\\\n",
    "    --learning_rate=0.01 \\\n",
    "    --batch_size=2 \\\n",
    "    --model=$MODEL_TYPE \\\n",
    "    --augment=True \\\n",
    "    --train_data_path=gs://cloud-ml-data/img/flowers_photos/train_set.csv \\\n",
    "    --eval_data_path=gs://cloud-ml-data/img/flowers_photos/eval_set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do it on ML Engine. Note the --model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/flowers/trained_${MODEL_TYPE}\n",
    "JOBNAME=flowers_${MODEL_TYPE}_$(date -u + %y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=flowersmodel_augment_tf_v_2_1.task \\\n",
    "    --package-path=./flowersmodel_augment_tf_v_2_1 \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=BASIC_GPU \\\n",
    "    --runtime-version=$TFVERSION \\\n",
    "    -- \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --train_steps=1000 \\\n",
    "    --learning_rate=0.01 \\\n",
    "    --batch_size=40 \\\n",
    "    --model=$MODEL_TYPE \\\n",
    "    --augment=True \\\n",
    "    --batch_norm=True \\\n",
    "    --train_data_path=gs://cloud-ml-data/img/flower_photos/train_set.csv \\\n",
    "    --eval_data_path=gs://cloud-ml-data/img/flower_photos/eval_set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"flowers\"\n",
    "MODEL_VERSION=${MODEL_TYPE}\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/flowers/trained_${MODEL_TYPE}/export/exporter | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ...this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete --quiet ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions ${REGION}\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, let's take one of the example images that is available on Google Cloud Storage <img src=\"http://storage.googleapis.com/cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The online prediction service expects images to be base64 encoded as described [here](https://cloud.google.com/ml-engine/docs/tensorflow/online-predict#binary_data_in_prediction_input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "IMAGE_URL=gs://cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg\n",
    "\n",
    "# Copy the image to local disk.\n",
    "gsutil cp $IMAGE_URL flower.jpg\n",
    "\n",
    "# Base64 encode and create request message in json format.\n",
    "python -c 'import base64, sys, json; img = base64.b64encode(open(\"flower.jpg\", \"rb\").read()).decode(); print(json.dumps({\"image_bytes\":{\"b64\": img}}))' &> request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send it to the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict \\\n",
    "    --model=flowers \\\n",
    "    --version=${MODEL_TYPE} \\\n",
    "    --json-instances=./request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
