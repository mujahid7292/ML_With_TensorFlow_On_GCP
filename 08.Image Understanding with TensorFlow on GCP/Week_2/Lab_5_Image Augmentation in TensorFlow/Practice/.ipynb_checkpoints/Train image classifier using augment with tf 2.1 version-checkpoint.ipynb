{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"ml-practice-260405\"\n",
    "BUCKET = \"bucket-ml-practice-260405\"\n",
    "REGION = \"us-central1\"\n",
    "MODEL_TYPE = \"cnn\"  # \"linear\", \"dnn\", \"dnn_dropout\", or \"cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change \n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"MODEL_TYPE\"] = MODEL_TYPE\n",
    "os.environ[\"TFVERSION\"] = \"2.1\"  # Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir flowersmodel_augment_tf_v_2_1\n",
    "mkdir flowersmodel_augment_tf_v_2_1/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flowersmodel_augment_tf_v_2_1/trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flowersmodel_augment_tf_v_2_1/trainer/__init__.py\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flowersmodel_augment_tf_v_2_1/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flowersmodel_augment_tf_v_2_1/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from . import model\n",
    "import tensorflow as tf\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Input Arguments\n",
    "    parser.add_argument(\n",
    "        '--batch_size',\n",
    "        help=\"Batch size for training steps.\",\n",
    "        type=int,\n",
    "        default=100\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--learning_rate',\n",
    "        help=\"Initial learning rate for training.\",\n",
    "        type=float,\n",
    "        default=0.01\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--train_steps',\n",
    "        help=\"Steps to run the train jobs for. A step is one batch size.\",\n",
    "        type=int,\n",
    "        default=100\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--output_dir',\n",
    "        help=\"GCS location to write checkpoints and export model\",\n",
    "        required=True\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--train_data_path',\n",
    "        help=\"Location of train file, which contain training image URL with appropriate label.\",\n",
    "        default=\"gs://cloud-ml-data/img/flower_photos/train_set.csv\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--eval_data_path',\n",
    "        help=\"Location of eval file, which contain evaluation image URL with appropriate label.\",\n",
    "        default=\"gs://cloud-ml-data/img/flower_photos/eval_set.csv\"\n",
    "    )\n",
    "\n",
    "    # Build list model_fn's for help message.\n",
    "    model_names = [name.replace(\"_model\", \"\") for name in dir(model) if name.endswith('_model')]\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--model',\n",
    "        help=\"Type of model. Supported types are {}\".format(model_names),\n",
    "        required=True\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help=\"This model ignore this field, but it is required by gcloud.\",\n",
    "        default='junk'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--augment',\n",
    "        help=\"If specified augment image data.\",\n",
    "        dest='augment',\n",
    "        action='store_true'\n",
    "    )\n",
    "\n",
    "    parser.set_defaults(augment=False)\n",
    "\n",
    "    # Optional hyper parameter used by cnn.\n",
    "    parser.add_argument(\n",
    "        '--ksize1',\n",
    "        help=\"Kernel size of the first layer of the cnn.\",\n",
    "        type=int,\n",
    "        default=5\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--ksize2',\n",
    "        help=\"Kernel size of the second layer of the cnn.\",\n",
    "        type=int,\n",
    "        default=5\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--nfil1',\n",
    "        help=\"Number of filters in the first layer of the cnn.\",\n",
    "        type=int,\n",
    "        default=10\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--nfil2',\n",
    "        help=\"Number of filters in the second layer of the cnn.\",\n",
    "        type=int,\n",
    "        default=20\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--dprob',\n",
    "        help=\"Dropout probability for cnn\",\n",
    "        type=float,\n",
    "        default=0.25\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--batch_norm',\n",
    "        help=\"If specified do batch norm for CNN\",\n",
    "        dest=\"batch_norm\",\n",
    "        action=\"store_true\"\n",
    "    )\n",
    "\n",
    "    parser.set_defaults(batch_norm = False)\n",
    "\n",
    "    args= parser.parse_args()\n",
    "    hparams = args.__dict__\n",
    "\n",
    "    output_dir = hparams.pop('output_dir')\n",
    "\n",
    "    # Appends trail id to path for hyper parameter tunning.\n",
    "    output_dir = os.path.join(\n",
    "        output_dir,\n",
    "        json.loads(\n",
    "            os.environ.get(\"TF_CONFIG\", \"{}\")\n",
    "        ).get(\"task\", {}).get(\"trail\", \"\")\n",
    "    )\n",
    "\n",
    "    # Run the training job.\n",
    "    model.train_and_evaluate(output_dir, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flowersmodel_augment_tf_v_2_1/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flowersmodel_augment_tf_v_2_1/trainer/model.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(\n",
    "    tf.compat.v1.logging.INFO\n",
    ")\n",
    "\n",
    "LIST_OF_LABELS = 'daisy,dandelion,roses,sunflowers,tulips'.split(',')\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "NUM_CHANNELS = 3\n",
    "NCLASSES = 5\n",
    "\n",
    "# Build Keras model using Keras Sequential API\n",
    "def linear_model(hparams):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS],\n",
    "        name=\"image\"\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name=\"probabilities\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def dnn_model(hparams):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS],\n",
    "        name=\"image\"\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=300,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=100,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=30,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name=\"probabilities\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def dnn_dropout_model(hparams):\n",
    "    dprob = hparams.get(\"dprob\", 0.10)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS],\n",
    "        name=\"image\"\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=300,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=100,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=30,\n",
    "        activation=tf.nn.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=dprob\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name=\"probabilities\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def cnn_model(hparams):\n",
    "    ksize1 = hparams.get(\"ksize1\", 5)\n",
    "    ksize2 = hparams.get(\"ksize2\", 5)\n",
    "    nfil1 = hparams.get(\"nfil1\", 10)\n",
    "    nfil2 = hparams.get(\"nfil2\", 20)\n",
    "    dprob = hparams.get(\"dprob\", 0.25)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS],\n",
    "        name=\"image\"\n",
    "    )) # Shape = (?, 224, 224, 3)\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=nfil1,\n",
    "        kernel_size=ksize1,\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )) # Shape = (?, 224, 224, nfil1)\n",
    "    model.add(tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2\n",
    "    )) # Shape = (?, 112, 112, nfil1)\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=nfil2,\n",
    "        kernel_size=ksize2,\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu\n",
    "    )) # Shape = (?, 112, 112, nfil2)\n",
    "    model.add(tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2\n",
    "    )) # Shape = (?, 56, 56, nfil2)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    # Apply batch normalization.\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=300,\n",
    "            activation=tf.nn.relu\n",
    "        ))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Activation(\n",
    "            activation=tf.nn.relu\n",
    "        ))\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=300,\n",
    "            activation=tf.nn.relu\n",
    "        ))\n",
    "    \n",
    "    # Apply Dropout\n",
    "    model.add(tf.keras.layers.Dropout(\n",
    "        rate=dprob\n",
    "    ))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=None\n",
    "    ))\n",
    "    \n",
    "    # Apply Batch Normalization once more.\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    # SoftMax Layer.\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=NCLASSES,\n",
    "        activation=tf.nn.softmax,\n",
    "        name=\"probabilities\"\n",
    "    ))\n",
    "    \n",
    "    return model\n",
    "\n",
    "MAX_DELTA = 63.0 / 255.0 # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "def read_and_preprocess(image_bytes, label=None, augment=False):\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(\n",
    "        contents=image_bytes,\n",
    "        channels=NUM_CHANNELS\n",
    "    )\n",
    "    # Use 'convert_image_dtype' to converts to floats in the \n",
    "    # [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(\n",
    "        image=img,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    # Resize the image to a desired size.\n",
    "    img = tf.image.resize(\n",
    "        images=img,\n",
    "        size=[IMG_HEIGHT + 10, IMG_WIDTH + 10],\n",
    "    )\n",
    "    \n",
    "    if augment:\n",
    "        img = tf.image.random_crop(\n",
    "            value=img,\n",
    "            size=[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS]\n",
    "        )\n",
    "        img = tf.image.random_flip_left_right(\n",
    "            image=img\n",
    "        )\n",
    "        img = tf.image.random_brightness(\n",
    "            image=img,\n",
    "            max_delta=MAX_DELTA\n",
    "        )\n",
    "        img = tf.image.random_contrast(\n",
    "            image=img,\n",
    "            lower=CONTRAST_LOWER,\n",
    "            upper=CONTRAST_UPPER\n",
    "        )\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def read_and_preprocess_with_augment(image_bytes, label=None):\n",
    "    return read_and_preprocess(\n",
    "        image_bytes=image_bytes,\n",
    "        label=label,\n",
    "        augment=True\n",
    "    )\n",
    "\n",
    "# Create Serving input function for inference.\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        \"image_bytes\":tf.compat.v1.placeholder(\n",
    "            dtype=tf.string,\n",
    "            shape=[]\n",
    "        )\n",
    "    }\n",
    "    img = read_and_preprocess(\n",
    "        image_bytes=feature_placeholders[\"image_bytes\"]\n",
    "    )\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=img,\n",
    "        receiver_tensors=feature_placeholders,\n",
    "    )\n",
    "\n",
    "def make_input_fn(csv_of_filenames, batch_size, training=True, augment=False):\n",
    "    def _input_fn():\n",
    "        def decode_csv(csv_row):\n",
    "            record_defaults = [\"path\", \"flowers\"]\n",
    "            filename, label_string = tf.io.decode_csv(\n",
    "                records=csv_row,\n",
    "                record_defaults=record_defaults\n",
    "            )\n",
    "            image_bytes = tf.io.read_file(\n",
    "                filename=filename\n",
    "            )\n",
    "            label = tf.math.equal(LIST_OF_LABELS, label_string)\n",
    "            return image_bytes, label\n",
    "        \n",
    "        # Create tf.data.dataset from filename\n",
    "        dataset = tf.data.TextLineDataset(\n",
    "            filenames=csv_of_filenames\n",
    "        ).map(decode_csv)\n",
    "        \n",
    "        if augment:\n",
    "            dataset = dataset.map(read_and_preprocess_with_augment)\n",
    "        else:\n",
    "            dataset = dataset.map(read_and_preprocess)\n",
    "            \n",
    "        if training:\n",
    "            num_epochs = None # Indefinately\n",
    "            dataset = dataset.shuffle(\n",
    "                buffer_size = 10 * batch_size\n",
    "            ) \n",
    "        else:\n",
    "            num_epochs=1 # Each photo used once\n",
    "            \n",
    "        dataset = dataset.repeat(\n",
    "            count=num_epochs\n",
    "        ).batch(batch_size=batch_size)\n",
    "        \n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    return _input_fn\n",
    "\n",
    "# Wrapper function to build selected Keras model type.\n",
    "def image_classifier(hparams):\n",
    "    model_functions = {\n",
    "        \"linear\": linear_model,\n",
    "        \"dnn\": dnn_model,\n",
    "        \"dnn_dropout\":dnn_dropout_model,\n",
    "        \"cnn\":cnn_model\n",
    "    }\n",
    "    \n",
    "    # Get function pointer for selected model type\n",
    "    model_function = model_functions[hparams[\"model\"]]\n",
    "    \n",
    "    # Build selected Keras model.\n",
    "    model = model_function(hparams)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create train_and_evaluate function.\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
